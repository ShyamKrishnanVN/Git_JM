{"cells": [{"cell_type": "code", "metadata": {"id": "199131145_0.49328393835537176"}, "execution_count": null, "source": ["from Notebook.DSNotebook.NotebookExecutor import NotebookExecutor\nnb = NotebookExecutor()\ndf = nb.get_data('17171692941396512', '@SYS.USERID', 'True', {}, [])\ndf1.head(27) "], "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "199131145_0.1952579016111231"}, "execution_count": null, "source": ["#New"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "199131145_0.05955103063964984"}, "execution_count": null, "source": ["#Changes in the GIiT version are updated and ready to push."], "outputs": []}, {"cell_type": "code", "metadata": {"id": "199131145_0.39332549015343443"}, "execution_count": null, "source": ["import pandas as pds\nfrom time import perf_counter as get_time\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Define the necessary variables here\n_data   = df   # pd.DataFrame: Full data to process\n_target = 'sex'    # string: Column name of the target variable\n\nif _data is None or _target is None:\n    raise Exception(f'Both _data and _target must be specified')\nelif not (isinstance(_data, pd.DataFrame) and isinstance(_target, str)):\n    raise Exception(f'Datatype of _data must be pd.DataFrame; that of _target must be str')\n\n# Separating the independent and dependent variables into X and y respectively\ny = _data[_target]\nX = _data.drop(columns=_target)\nprint(f'Shape of complete data: {_data.shape}')\n\n# Splitting the dataset into training and testing datasets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\nprint(f'Shape of training data: {X_train.shape}')\nprint(f'Shape of testing data : {X_test.shape}')\n\n# Creating the classifier and fitting it to the training data\nknn_clf = KNeighborsClassifier()\ntime_now = get_time()\nknn_clf.fit(X_train, y_train);\nprint(f'Model {knn_clf} trained')\nprint(f'Seconds elapsed: {round(get_time() - time_now, 3)}')\n\n# Making predictions on the training data\npredict_train = knn_clf.predict(X_train)\nprint(f'Predictions on training data made')\n\n# Finding the accuracy score of the training predictions\naccuracy_train = accuracy_score(y_train, predict_train)\nprint(f'Accuracy score of training predictions: {round(accuracy_train, 3)}')\n\n# Printing the classification report of the training predictions\nreport_train = classification_report(y_train, predict_train, digits=3)\nprint(f'Classification report of training predictions:')\nprint(report_train)\n\n# Making predictions on the testing data\npredict_test = knn_clf.predict(X_test)\nprint(f'Predictions on testing data made')\n\n# Finding the accuracy score of the testing predictions\naccuracy_test = accuracy_score(y_test, predict_test)\nprint(f'Accuracy score of testing predictions: {round(accuracy_test, 3)}')\n\n# Printing the classification report of the testing predictions\nreport_test = classification_report(y_test, predict_test, digits=3)\nprint(f'Classification report of testing predictions:')\nprint(report_test)"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "199131145_0.8703469882047763"}, "execution_count": null, "source": ["from Notebook.DSNotebook.NotebookExecutor import NotebookExecutor\nnb = NotebookExecutor()\nsaved_model = nb.save_model(model = knn_clf, modelName = 'KNN Classifier_V1.dill', modelType = 'ml', X = None, y = None, estimator_type='')\n#X and y are training datasets to get explainer dashboard.\n#estimator_type is to specify algorithm type i.e., classification and regression.\n#Only 'ml\u2019 models with tabular data as input will support in Explainer Dashboard.\n#Choose modelType = 'ml' for machine learning models, modelType = 'cv' for computer vision models and modelType = 'dp' for data transformation pickle files. \n#Provide \u2018column_headers\u2019 as a parameter if they have to be saved in the model.\n#If using custom layer in keras, use native save functionality from keras."], "outputs": []}, {"cell_type": "code", "metadata": {"id": "199131145_0.9461318591094869"}, "execution_count": null, "source": ["def AB_InBev():\n    from Notebook.DSNotebook.NotebookExecutor import NotebookExecutor\n    nb = NotebookExecutor()\n    df = nb.get_data('17171692941396512', '@SYS.USERID', 'True', {}, [])\n    column_to_drop = 'sex'\n    df_test = df.drop(columns=[column_to_drop])\n    return df_test"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "199131145_0.7585042635182502"}, "execution_count": null, "source": ["AB_In()"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "34963538_0.7625240808380713"}, "execution_count": null, "source": ["import logging"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "34963538_0.9375595436045214"}, "execution_count": null, "source": ["logging.info(\"test\")"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "34963538_0.3099294287980041"}, "execution_count": null, "source": ["from Notebook.DSNotebook.NotebookExecutor import NotebookExecutor\nnb = NotebookExecutor()\ndf_Dump_Again = nb.get_data('11561698320754285', '@SYS.USERID', 'True', {}, [])\ndf_Dump_Again.head()"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "34963538_0.9784065129517847"}, "execution_count": null, "source": ["chdir(@SYS.DATASANDBOX_PATH + '34930693/Repo')"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "34963538_0.6342830109037543"}, "execution_count": null, "source": ["getcwd()"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "34963538_0.25974070893866674"}, "execution_count": null, "source": ["df_Dump_Again.to_csv(\"New.csv\")"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "34963538_0.7849342126295076"}, "execution_count": null, "source": ["pd.read_csv(@SYS.DATASANDBOX_PATH + '34930693/Data/New.csv')"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "34963538_0.5020597669803493"}, "execution_count": null, "source": ["from Notebook.DSNotebook.NotebookExecutor import NotebookExecutor\nnb = NotebookExecutor()\n#File extension should be with .csv/.json/.txt\nnb.save_artifact(dataframe = df_Dump_Again, name = 'df_Dump_Again_V1.csv')"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "34963538_0.615985978355869"}, "execution_count": null, "source": ["@SYS.DATASANDBOX_PATH + '34930693/Data'"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "34963538_0.7583440262099503"}, "execution_count": null, "source": ["from os import *"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "34963538_0.8133348909082008"}, "execution_count": null, "source": ["listdir()"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "34963538_0.9401628834801297"}, "execution_count": null, "source": ["getcwd()"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "34963538_0.02677955024980494"}, "execution_count": null, "source": ["a = @SYS.DATASANDBOX_PATH + '34930693'"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "34963538_0.8680873104877298"}, "execution_count": null, "source": ["a"], "outputs": []}], "metadata": {}, "nbformat": 4, "nbformat_minor": 2}
