{"dslabserviceresp":{"bizvizWorkspace":"{\"reserv1\":null,\"reserv2\":null,\"reserv3\":null,\"reserv4\":null,\"reserv5\":null,\"createdDate\":1696923171345,\"isActive\":0,\"lastUpdatedDate\":null,\"active\":1,\"migrationId\":null,\"id\":182255630,\"name\":\"Test Git JM\",\"count\":null,\"parentId\":null,\"userId\":\"183205890\",\"isFile\":false,\"infoJson\":\"{\\\"imageVersion\\\":\\\"8.0.24\\\",\\\"external_libraries\\\":\\\"\\\",\\\"imageName\\\":\\\"reg-dev.bdb.ai/release/dsnotebook-tensorflow\\\",\\\"confDetails\\\":{\\\"high\\\":{\\\"nonspark\\\":{\\\"request\\\":{\\\"memory\\\":\\\"2048Mi\\\",\\\"cpu\\\":\\\"1000m\\\"},\\\"limit\\\":{\\\"memory\\\":\\\"4048Mi\\\",\\\"cpu\\\":\\\"2500m\\\"}}},\\\"low\\\":{\\\"realtime\\\":{\\\"nonspark\\\":{\\\"request\\\":{\\\"memory\\\":\\\"1024Mi\\\",\\\"cpu\\\":\\\"500m\\\"},\\\"limit\\\":{\\\"memory\\\":\\\"1024Mi\\\",\\\"cpu\\\":\\\"1000m\\\"}}}},\\\"medium\\\":{\\\"nonspark\\\":{\\\"request\\\":{\\\"memory\\\":\\\"4096Mi\\\",\\\"cpu\\\":\\\"1000m\\\"},\\\"limit\\\":{\\\"memory\\\":\\\"5048Mi\\\",\\\"cpu\\\":\\\"1000m\\\"}}}},\\\"idle_shutdown\\\":\\\"1h\\\",\\\"apiImageVersion\\\":\\\"8.0.99\\\",\\\"appName\\\":\\\"testgitjm-gcho\\\",\\\"git_project\\\":\\\"\\\",\\\"project_url\\\":\\\"vnshyamkrishnan/gitpush_jm\\\",\\\"project_name\\\":\\\"Test Git JM\\\",\\\"removedLibraries\\\":\\\"\\\",\\\"environment\\\":\\\"PythonTensorFlow\\\",\\\"project_description\\\":\\\"New\\\",\\\"Algorithms\\\":\\\"\\\",\\\"gpuLimit\\\":\\\"\\\",\\\"resource_allocation\\\":\\\"medium\\\",\\\"configured_branch\\\":\\\"main\\\",\\\"apiImageName\\\":\\\"reg-dev.bdb.ai/release/dsmodelapi\\\",\\\"gpuType\\\":\\\"\\\"}\",\"spaceKey\":\"7760\",\"type\":10,\"status\":1,\"contentJson\":\"{\\\"CreateProjectKey\\\":\\\"Create_Project\\\"}\",\"templateJson\":null,\"isShared\":null,\"updatedBy\":\"183205891\",\"uuid\":\"77601696923171345\",\"createdUserName\":null}","envVariables":[],"utility":"[{\"migrationId\":null,\"id\":185991236,\"spaceKey\":\"7760\",\"name\":\"Utiity_script_V32\",\"description\":\"from vcs imported file\",\"createdDate\":1697022604000,\"lastUpdatedDate\":1697022604000,\"createdBy\":183205890,\"updatedBy\":183205890,\"properties\":\"{\\\"metadata\\\":\\\"Utiity_script_V32.py\\\",\\\"filename\\\":\\\"Utiity_script_V32.py\\\",\\\"isImported\\\":1,\\\"last_modified_date\\\":\\\"2023-10-11T11:09:31.000+00:00\\\"}\",\"status\":1,\"completionStatus\":1,\"type\":\"py\",\"reference_id\":182255630,\"prepJson\":null,\"uuid\":\"77601697022534052\",\"fileType\":null,\"createdTime\":null},{\"migrationId\":null,\"id\":184975387,\"spaceKey\":\"7760\",\"name\":\"Utiity_script_V31\",\"description\":\"from vcs imported file\",\"createdDate\":1696944768000,\"lastUpdatedDate\":1696944768000,\"createdBy\":183205891,\"updatedBy\":183205891,\"properties\":\"{\\\"filename\\\":\\\"Utiity_script_V31.py\\\",\\\"isImported\\\":1}\",\"status\":1,\"completionStatus\":1,\"type\":\"py\",\"reference_id\":182255630,\"prepJson\":null,\"uuid\":\"77601696944768376\",\"fileType\":null,\"createdTime\":null}]","notebookContent":"{\"nbformat_minor\":2,\"metadata\":{},\"cells\":[{\"outputs\":[{\"output_type\":\"stream\",\"name\":\"stdout\",\"text\":[\"test123\\n\"]}],\"metadata\":{\"id\":\"181960737_0.638626893745081\"},\"execution_count\":2,\"source\":[\"import logging\\n\\nlogging.info(\\\"Test\\\")\\nprint(\\\"test\\\")\\n\\n#Test\"],\"cell_type\":\"code\"},{\"outputs\":[{\"ename\":\"Exception\",\"output_type\":\"error\",\"evalue\":\"'queryService'\",\"traceback\":[\"---------------------------------------------------------------------------\",\"Exception                                 Traceback (most recent call last)\",\"Cell In[2], line 3\\n      1 from Notebook.DSNotebook.NotebookExecutor import NotebookExecutor\\n      2 nb = NotebookExecutor()\\n----> 3 df = nb.get_data('17171692941396512', '183205891', 'True', {}, [])\\n      4 df.head()\\n\",\"File /app/Notebook/DSNotebook/NotebookExecutor.py:1154, in NotebookExecutor.get_data(self, serviceID, UserID, Sandbox, filters, prep_ids, limit, spark)\\n   1152     return df\\n   1153 except Exception as e:\\n-> 1154     raise Exception(e) from None\\n\",\"Exception: 'queryService'\"]}],\"metadata\":{\"id\":\"181960737_0.05305180789617059\"},\"execution_count\":1,\"source\":[\"from Notebook.DSNotebook.NotebookExecutor import NotebookExecutor\\nnb = NotebookExecutor()\\ndf = nb.get_data('17171692941396512', '@SYS.USERID', 'True', {}, [])\\ndf.head()\\n\\n#This wont work\"],\"cell_type\":\"code\"},{\"outputs\":[],\"metadata\":{\"id\":\"181960737_0.9415806370555642\"},\"execution_count\":null,\"source\":[\"#Changes in the GIT version are updated and ready to push.\"],\"cell_type\":\"code\"},{\"outputs\":[],\"metadata\":{\"id\":\"181960737_0.6143141248547768\"},\"execution_count\":null,\"source\":[\"import pandas as pd\\nfrom time import perf_counter as get_time\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.neighbors import KNeighborsClassifier\\nfrom sklearn.metrics import accuracy_score, classification_report\\n\\n# Define the necessary variables here\\n_data   = df   # pd.DataFrame: Full data to process\\n_target = 'sex'    # string: Column name of the target variable\\n\\nif _data is None or _target is None:\\n    raise Exception(f'Both _data and _target must be specified')\\nelif not (isinstance(_data, pd.DataFrame) and isinstance(_target, str)):\\n    raise Exception(f'Datatype of _data must be pd.DataFrame; that of _target must be str')\\n\\n# Separating the independent and dependent variables into X and y respectively\\ny = _data[_target]\\nX = _data.drop(columns=_target)\\nprint(f'Shape of complete data: {_data.shape}')\\n\\n# Splitting the dataset into training and testing datasets\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\\nprint(f'Shape of training data: {X_train.shape}')\\nprint(f'Shape of testing data : {X_test.shape}')\\n\\n# Creating the classifier and fitting it to the training data\\nknn_clf = KNeighborsClassifier()\\ntime_now = get_time()\\nknn_clf.fit(X_train, y_train);\\nprint(f'Model {knn_clf} trained')\\nprint(f'Seconds elapsed: {round(get_time() - time_now, 3)}')\\n\\n# Making predictions on the training data\\npredict_train = knn_clf.predict(X_train)\\nprint(f'Predictions on training data made')\\n\\n# Finding the accuracy score of the training predictions\\naccuracy_train = accuracy_score(y_train, predict_train)\\nprint(f'Accuracy score of training predictions: {round(accuracy_train, 3)}')\\n\\n# Printing the classification report of the training predictions\\nreport_train = classification_report(y_train, predict_train, digits=3)\\nprint(f'Classification report of training predictions:')\\nprint(report_train)\\n\\n# Making predictions on the testing data\\npredict_test = knn_clf.predict(X_test)\\nprint(f'Predictions on testing data made')\\n\\n# Finding the accuracy score of the testing predictions\\naccuracy_test = accuracy_score(y_test, predict_test)\\nprint(f'Accuracy score of testing predictions: {round(accuracy_test, 3)}')\\n\\n# Printing the classification report of the testing predictions\\nreport_test = classification_report(y_test, predict_test, digits=3)\\nprint(f'Classification report of testing predictions:')\\nprint(report_test)\"],\"cell_type\":\"code\"},{\"outputs\":[],\"metadata\":{\"id\":\"181960737_0.1590922199878828\"},\"execution_count\":null,\"source\":[\"from Notebook.DSNotebook.NotebookExecutor import NotebookExecutor\\nnb = NotebookExecutor()\\nsaved_model = nb.save_model(model = knn_clf, modelName = 'KNN Classifier_V1.dill', modelType = 'ml', X = None, y = None, estimator_type='')\\n#X and y are training datasets to get explainer dashboard.\\n#estimator_type is to specify algorithm type i.e., classification and regression.\\n#Only 'ml\\u2019 models with tabular data as input will support in Explainer Dashboard.\\n#Choose modelType = 'ml' for machine learning models, modelType = 'cv' for computer vision models and modelType = 'dp' for data transformation pickle files. \\n#Provide \\u2018column_headers\\u2019 as a parameter if they have to be saved in the model.\\n#If using custom layer in keras, use native save functionality from keras.\"],\"cell_type\":\"code\"},{\"outputs\":[],\"metadata\":{\"id\":\"181960737_0.6054463605526541\"},\"execution_count\":null,\"source\":[\"def AB_In():\\n    from Notebook.DSNotebook.NotebookExecutor import NotebookExecutor\\n    nb = NotebookExecutor()\\n    df = nb.get_data('17171692941396512', '@SYS.USERID', 'True', {}, [])\\n    column_to_drop = 'sex'\\n    df_test = df.drop(columns=[column_to_drop])\\n    return df_test\"],\"cell_type\":\"code\"},{\"outputs\":[],\"metadata\":{\"id\":\"181960737_0.20826298328061088\"},\"execution_count\":null,\"source\":[\"AB_In()\"],\"cell_type\":\"code\"}],\"nbformat\":4}","secrets":"{\"reserv1\":null,\"reserv2\":null,\"reserv3\":null,\"reserv4\":null,\"reserv5\":null,\"createdDate\":null,\"isActive\":0,\"lastUpdatedDate\":null,\"active\":1,\"migrationId\":null,\"id\":22118400,\"type\":\"210\",\"status\":1,\"spaceKey\":\"2547\",\"settings\":\"[]\"}","notebook":"{\"migrationId\":null,\"id\":181960737,\"projectId\":182255630,\"spaceKey\":\"7760\",\"notebookName\":\"Input_Abalone_V2\",\"data\":\"{\\\"filename\\\":\\\"Input_Abalone_V2.ipynb\\\",\\\"sucess\\\":true,\\\"content\\\":{\\\"nbformat_minor\\\":2,\\\"metadata\\\":{},\\\"cells\\\":[{\\\"outputs\\\":[{\\\"output_type\\\":\\\"stream\\\",\\\"name\\\":\\\"stdout\\\",\\\"text\\\":[\\\"test123\\\\n\\\"]}],\\\"metadata\\\":{\\\"id\\\":\\\"181960737_0.638626893745081\\\"},\\\"execution_count\\\":2,\\\"source\\\":[\\\"import logging\\\\n\\\\nlogging.info(\\\\\\\"Test\\\\\\\")\\\\nprint(\\\\\\\"test\\\\\\\")\\\\n\\\\n#Test\\\"],\\\"cell_type\\\":\\\"code\\\"},{\\\"outputs\\\":[{\\\"ename\\\":\\\"Exception\\\",\\\"output_type\\\":\\\"error\\\",\\\"evalue\\\":\\\"'queryService'\\\",\\\"traceback\\\":[\\\"---------------------------------------------------------------------------\\\",\\\"Exception                                 Traceback (most recent call last)\\\",\\\"Cell In[2], line 3\\\\n      1 from Notebook.DSNotebook.NotebookExecutor import NotebookExecutor\\\\n      2 nb = NotebookExecutor()\\\\n----> 3 df = nb.get_data('17171692941396512', '183205891', 'True', {}, [])\\\\n      4 df.head()\\\\n\\\",\\\"File /app/Notebook/DSNotebook/NotebookExecutor.py:1154, in NotebookExecutor.get_data(self, serviceID, UserID, Sandbox, filters, prep_ids, limit, spark)\\\\n   1152     return df\\\\n   1153 except Exception as e:\\\\n-> 1154     raise Exception(e) from None\\\\n\\\",\\\"Exception: 'queryService'\\\"]}],\\\"metadata\\\":{\\\"id\\\":\\\"181960737_0.05305180789617059\\\"},\\\"execution_count\\\":1,\\\"source\\\":[\\\"from Notebook.DSNotebook.NotebookExecutor import NotebookExecutor\\\\nnb = NotebookExecutor()\\\\ndf = nb.get_data('17171692941396512', '@SYS.USERID', 'True', {}, [])\\\\ndf.head()\\\\n\\\\n#This wont work\\\"],\\\"cell_type\\\":\\\"code\\\"},{\\\"outputs\\\":[],\\\"metadata\\\":{\\\"id\\\":\\\"181960737_0.9415806370555642\\\"},\\\"execution_count\\\":null,\\\"source\\\":[\\\"#Changes in the GIT version are updated and ready to push.\\\"],\\\"cell_type\\\":\\\"code\\\"},{\\\"outputs\\\":[],\\\"metadata\\\":{\\\"id\\\":\\\"181960737_0.6143141248547768\\\"},\\\"execution_count\\\":null,\\\"source\\\":[\\\"import pandas as pd\\\\nfrom time import perf_counter as get_time\\\\nfrom sklearn.model_selection import train_test_split\\\\nfrom sklearn.neighbors import KNeighborsClassifier\\\\nfrom sklearn.metrics import accuracy_score, classification_report\\\\n\\\\n# Define the necessary variables here\\\\n_data   = df   # pd.DataFrame: Full data to process\\\\n_target = 'sex'    # string: Column name of the target variable\\\\n\\\\nif _data is None or _target is None:\\\\n    raise Exception(f'Both _data and _target must be specified')\\\\nelif not (isinstance(_data, pd.DataFrame) and isinstance(_target, str)):\\\\n    raise Exception(f'Datatype of _data must be pd.DataFrame; that of _target must be str')\\\\n\\\\n# Separating the independent and dependent variables into X and y respectively\\\\ny = _data[_target]\\\\nX = _data.drop(columns=_target)\\\\nprint(f'Shape of complete data: {_data.shape}')\\\\n\\\\n# Splitting the dataset into training and testing datasets\\\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\\\\nprint(f'Shape of training data: {X_train.shape}')\\\\nprint(f'Shape of testing data : {X_test.shape}')\\\\n\\\\n# Creating the classifier and fitting it to the training data\\\\nknn_clf = KNeighborsClassifier()\\\\ntime_now = get_time()\\\\nknn_clf.fit(X_train, y_train);\\\\nprint(f'Model {knn_clf} trained')\\\\nprint(f'Seconds elapsed: {round(get_time() - time_now, 3)}')\\\\n\\\\n# Making predictions on the training data\\\\npredict_train = knn_clf.predict(X_train)\\\\nprint(f'Predictions on training data made')\\\\n\\\\n# Finding the accuracy score of the training predictions\\\\naccuracy_train = accuracy_score(y_train, predict_train)\\\\nprint(f'Accuracy score of training predictions: {round(accuracy_train, 3)}')\\\\n\\\\n# Printing the classification report of the training predictions\\\\nreport_train = classification_report(y_train, predict_train, digits=3)\\\\nprint(f'Classification report of training predictions:')\\\\nprint(report_train)\\\\n\\\\n# Making predictions on the testing data\\\\npredict_test = knn_clf.predict(X_test)\\\\nprint(f'Predictions on testing data made')\\\\n\\\\n# Finding the accuracy score of the testing predictions\\\\naccuracy_test = accuracy_score(y_test, predict_test)\\\\nprint(f'Accuracy score of testing predictions: {round(accuracy_test, 3)}')\\\\n\\\\n# Printing the classification report of the testing predictions\\\\nreport_test = classification_report(y_test, predict_test, digits=3)\\\\nprint(f'Classification report of testing predictions:')\\\\nprint(report_test)\\\"],\\\"cell_type\\\":\\\"code\\\"},{\\\"outputs\\\":[],\\\"metadata\\\":{\\\"id\\\":\\\"181960737_0.1590922199878828\\\"},\\\"execution_count\\\":null,\\\"source\\\":[\\\"from Notebook.DSNotebook.NotebookExecutor import NotebookExecutor\\\\nnb = NotebookExecutor()\\\\nsaved_model = nb.save_model(model = knn_clf, modelName = 'KNN Classifier_V1.dill', modelType = 'ml', X = None, y = None, estimator_type='')\\\\n#X and y are training datasets to get explainer dashboard.\\\\n#estimator_type is to specify algorithm type i.e., classification and regression.\\\\n#Only 'ml\\\\u2019 models with tabular data as input will support in Explainer Dashboard.\\\\n#Choose modelType = 'ml' for machine learning models, modelType = 'cv' for computer vision models and modelType = 'dp' for data transformation pickle files. \\\\n#Provide \\\\u2018column_headers\\\\u2019 as a parameter if they have to be saved in the model.\\\\n#If using custom layer in keras, use native save functionality from keras.\\\"],\\\"cell_type\\\":\\\"code\\\"},{\\\"outputs\\\":[],\\\"metadata\\\":{\\\"id\\\":\\\"181960737_0.6054463605526541\\\"},\\\"execution_count\\\":null,\\\"source\\\":[\\\"def AB_In():\\\\n    from Notebook.DSNotebook.NotebookExecutor import NotebookExecutor\\\\n    nb = NotebookExecutor()\\\\n    df = nb.get_data('17171692941396512', '@SYS.USERID', 'True', {}, [])\\\\n    column_to_drop = 'sex'\\\\n    df_test = df.drop(columns=[column_to_drop])\\\\n    return df_test\\\"],\\\"cell_type\\\":\\\"code\\\"},{\\\"outputs\\\":[],\\\"metadata\\\":{\\\"id\\\":\\\"181960737_0.20826298328061088\\\"},\\\"execution_count\\\":null,\\\"source\\\":[\\\"AB_In()\\\"],\\\"cell_type\\\":\\\"code\\\"}],\\\"nbformat\\\":4}}\",\"description\":null,\"createdDate\":1696933432971,\"lastUpdatedDate\":1697091026758,\"createdBy\":183205891,\"updatedBy\":183205890,\"status\":1,\"committedBy\":183205891,\"lastcommittedDate\":1696933432971,\"isShared\":null,\"customComponentscript\":\"{\\\"DSLAB_content\\\":\\\"[{\\\\\\\"id\\\\\\\":\\\\\\\"181960737_0.6054463605526541\\\\\\\",\\\\\\\"code\\\\\\\":\\\\\\\"def AB_In():\\\\\\\\n    from Notebook.DSNotebook.NotebookExecutor import NotebookExecutor\\\\\\\\n    nb = NotebookExecutor()\\\\\\\\n    df = nb.get_data('17171692941396512', '@SYS.USERID', 'True', {}, [])\\\\\\\\n    column_to_drop = 'sex'\\\\\\\\n    df_test = df.drop(columns=[column_to_drop])\\\\\\\\n    return df_test\\\\\\\",\\\\\\\"count\\\\\\\":0,\\\\\\\"error\\\\\\\":\\\\\\\"\\\\\\\",\\\\\\\"type\\\\\\\":\\\\\\\"code\\\\\\\",\\\\\\\"ischecked\\\\\\\":true}]\\\",\\\"pipeline_content\\\":\\\"\\\\\\\"def AB_In():\\\\\\\\n    from Notebook.DSNotebook.NotebookExecutor import NotebookExecutor\\\\\\\\n    nb = NotebookExecutor()\\\\\\\\n    df = nb.get_data('17171692941396512', '@SYS.USERID', 'True', {}, [])\\\\\\\\n    column_to_drop = 'sex'\\\\\\\\n    df_test = df.drop(columns=[column_to_drop])\\\\\\\\n    return df_test\\\\\\\"\\\",\\\"externalLibraries\\\":\\\"[]\\\"}\",\"type\":2,\"isScheduled\":null,\"isImported\":1,\"uuid\":\"77601696933432989\"}"}}