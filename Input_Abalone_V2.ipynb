{"cells": [{"cell_type": "code", "metadata": {"id": "181960737_0.638626893745081"}, "execution_count": 2, "source": ["import logging\n\nlogging.info(\"Test\")\nprint(\"test123\")\n\n#Test"], "outputs": [{"name": "stdout", "text": ["test123\n"], "output_type": "stream"}]}, {"cell_type": "code", "metadata": {"id": "181960737_0.05305180789617059"}, "execution_count": 1, "source": ["from Notebook.DSNotebook.NotebookExecutor import NotebookExecutor\nnb = NotebookExecutor()\ndf = nb.get_data('17171692941396512', '@SYS.USERID', 'True', {}, [])\ndf.head()\n\n#This wont work"], "outputs": [{"traceback": ["---------------------------------------------------------------------------", "Exception                                 Traceback (most recent call last)", "Cell In[2], line 3\n      1 from Notebook.DSNotebook.NotebookExecutor import NotebookExecutor\n      2 nb = NotebookExecutor()\n----> 3 df = nb.get_data('17171692941396512', '183205891', 'True', {}, [])\n      4 df.head()\n", "File /app/Notebook/DSNotebook/NotebookExecutor.py:1154, in NotebookExecutor.get_data(self, serviceID, UserID, Sandbox, filters, prep_ids, limit, spark)\n   1152     return df\n   1153 except Exception as e:\n-> 1154     raise Exception(e) from None\n", "Exception: 'queryService'"], "ename": "Exception", "evalue": "'queryService'", "output_type": "error"}]}, {"cell_type": "code", "metadata": {"id": "181960737_0.9415806370555642"}, "execution_count": null, "source": ["#Changes in the GIT version are updated and ready to push."], "outputs": []}, {"cell_type": "code", "metadata": {"id": "181960737_0.6143141248547768"}, "execution_count": null, "source": ["import pandas as pd\nfrom time import perf_counter as get_time\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Define the necessary variables here\n_data   = df   # pd.DataFrame: Full data to process\n_target = 'sex'    # string: Column name of the target variable\n\nif _data is None or _target is None:\n    raise Exception(f'Both _data and _target must be specified')\nelif not (isinstance(_data, pd.DataFrame) and isinstance(_target, str)):\n    raise Exception(f'Datatype of _data must be pd.DataFrame; that of _target must be str')\n\n# Separating the independent and dependent variables into X and y respectively\ny = _data[_target]\nX = _data.drop(columns=_target)\nprint(f'Shape of complete data: {_data.shape}')\n\n# Splitting the dataset into training and testing datasets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\nprint(f'Shape of training data: {X_train.shape}')\nprint(f'Shape of testing data : {X_test.shape}')\n\n# Creating the classifier and fitting it to the training data\nknn_clf = KNeighborsClassifier()\ntime_now = get_time()\nknn_clf.fit(X_train, y_train);\nprint(f'Model {knn_clf} trained')\nprint(f'Seconds elapsed: {round(get_time() - time_now, 3)}')\n\n# Making predictions on the training data\npredict_train = knn_clf.predict(X_train)\nprint(f'Predictions on training data made')\n\n# Finding the accuracy score of the training predictions\naccuracy_train = accuracy_score(y_train, predict_train)\nprint(f'Accuracy score of training predictions: {round(accuracy_train, 3)}')\n\n# Printing the classification report of the training predictions\nreport_train = classification_report(y_train, predict_train, digits=3)\nprint(f'Classification report of training predictions:')\nprint(report_train)\n\n# Making predictions on the testing data\npredict_test = knn_clf.predict(X_test)\nprint(f'Predictions on testing data made')\n\n# Finding the accuracy score of the testing predictions\naccuracy_test = accuracy_score(y_test, predict_test)\nprint(f'Accuracy score of testing predictions: {round(accuracy_test, 3)}')\n\n# Printing the classification report of the testing predictions\nreport_test = classification_report(y_test, predict_test, digits=3)\nprint(f'Classification report of testing predictions:')\nprint(report_test)"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "181960737_0.1590922199878828"}, "execution_count": null, "source": ["from Notebook.DSNotebook.NotebookExecutor import NotebookExecutor\nnb = NotebookExecutor()\nsaved_model = nb.save_model(model = knn_clf, modelName = 'KNN Classifier_V1.dill', modelType = 'ml', X = None, y = None, estimator_type='')\n#X and y are training datasets to get explainer dashboard.\n#estimator_type is to specify algorithm type i.e., classification and regression.\n#Only 'ml\u2019 models with tabular data as input will support in Explainer Dashboard.\n#Choose modelType = 'ml' for machine learning models, modelType = 'cv' for computer vision models and modelType = 'dp' for data transformation pickle files. \n#Provide \u2018column_headers\u2019 as a parameter if they have to be saved in the model.\n#If using custom layer in keras, use native save functionality from keras."], "outputs": []}, {"cell_type": "code", "metadata": {"id": "181960737_0.6054463605526541"}, "execution_count": null, "source": ["def AB_In():\n    from Notebook.DSNotebook.NotebookExecutor import NotebookExecutor\n    nb = NotebookExecutor()\n    df = nb.get_data('17171692941396512', '@SYS.USERID', 'True', {}, [])\n    column_to_drop = 'sex'\n    df_test = df.drop(columns=[column_to_drop])\n    return df_test"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "181960737_0.20826298328061088"}, "execution_count": null, "source": ["AB_In()"], "outputs": []}], "metadata": {}, "nbformat": 4, "nbformat_minor": 2}