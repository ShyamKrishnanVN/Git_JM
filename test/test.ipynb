{"cells": [{"cell_type": "code", "metadata": {"id": "158024330_0.11358885144625175"}, "execution_count": 1, "source": ["from Notebook.DSNotebook.NotebookExecutor import NotebookExecutor\nnb = NotebookExecutor()\ndf_Dump_Data = nb.get_data('11561697699506508', '@SYS.USERID','True', {},['11561710911349444'])\ndf_Dump_Data_V12\n# The first function parameter refers to the service ID of the dataset.\n# @SYS.USERID refers to the user ID of the current user.\n# If the Sandbox key is 'false', it is referred to as a dataset, and if it's 'true', then the file is a sandbox file.\n# {} refers to the filters applied to the dataset.\n# [] refers to the data preparations applied to the dataset.\n# After [], users can specify the number of rows to limit the headcount of the dataset with a comma separator."], "outputs": [{"name": "stdout", "text": "\nERROR:root:Error while readig data 11561697699506508 'queryService'\n", "output_type": "stream"}, {"traceback": ["---------------------------------------------------------------------------", "Exception                                 Traceback (most recent call last)", "Cell In[2], line 3\n      1 from Notebook.DSNotebook.NotebookExecutor import NotebookExecutor\n      2 nb = NotebookExecutor()\n----> 3 df_Dump_Data = nb.get_data('11561697699506508', '48201728','True', {},['11561710911349444'])\n      4 df_Dump_Data\n      5 # The first function parameter refers to the service ID of the dataset.\n      6 # 48201728 refers to the user ID of the current user.\n      7 # If the Sandbox key is 'false', it is referred to as a dataset, and if it's 'true', then the file is a sandbox file.\n      8 # {} refers to the filters applied to the dataset.\n      9 # [] refers to the data preparations applied to the dataset.\n     10 # After [], users can specify the number of rows to limit the headcount of the dataset with a comma separator.\n", "File /app/Notebook/DSNotebook/NotebookExecutor.py:1517, in NotebookExecutor.get_data(self, serviceID, UserID, Sandbox, filters, prep_ids, sheet_name, limit, spark, version)\n   1515 except Exception as e:\n   1516     logging.error(f\"Error while readig data {serviceID} {str(e)}\")\n-> 1517     raise Exception(e) from None\n   1518 finally:\n   1519     os.chdir(f'{os.environ[\"DATASANDBOX_PATH\"]}/{os.environ[\"SPACE_KEY\"]}/{os.environ[\"PROJECT_ID\"]}')\n", "Exception: 'queryService'"], "ename": "Exception", "evalue": "'queryService'", "output_type": "error"}]}, {"cell_type": "code", "execution_count": 3, "metadata": {"id": "1105185690_0.6989888257753105"}, "outputs": [], "source": ["import Repo.test.New_Test"]}, {"cell_type": "code", "execution_count": 4, "metadata": {"id": "1105185690_0.8635513062624689"}, "outputs": [], "source": ["import Repo.test.test"]}, {"cell_type": "code", "execution_count": 2, "metadata": {"id": "1924798845_0.8425072412317791"}, "outputs": [{"ename": "Exception", "evalue": "'prepDetails'", "output_type": "error", "traceback": ["---------------------------------------------------------------------------", "Exception                                 Traceback (most recent call last)", "Cell In[3], line 3\n      1 from Notebook.DSNotebook.NotebookExecutor import NotebookExecutor\n      2 nb = NotebookExecutor()\n----> 3 df_DS_Lab_MySQL = nb.get_data('11561705035891145', '950278','False', {},['11561710911386024'])\n      4 df_DS_Lab_MySQL\n      5 # The first function parameter refers to the service ID of the dataset.\n      6 # 950278 refers to the user ID of the current user.\n      7 # If the Sandbox key is 'false', it is referred to as a dataset, and if it's 'true', then the file is a sandbox file.\n      8 # {} refers to the filters applied to the dataset.\n      9 # [] refers to the data preparations applied to the dataset.\n     10 # After [], users can specify the number of rows to limit the headcount of the dataset with a comma separator.\n", "File /app/Notebook/DSNotebook/NotebookExecutor.py:1628, in NotebookExecutor.get_data(self, serviceID, UserID, Sandbox, filters, prep_ids, limit, spark)\n   1626 except Exception as e:\n   1627     logging.error(f\"Error while readig data {serviceID} {str(e)}\")\n-> 1628     raise Exception(e) from None\n   1629 finally:\n   1630     os.chdir(f'{os.environ[\"DATASANDBOX_PATH\"]}/{os.environ[\"SPACE_KEY\"]}/{os.environ[\"PROJECT_ID\"]}')\n", "Exception: 'prepDetails'"]}], "source": ["from Notebook.DSNotebook.NotebookExecutor import NotebookExecutor\nnb = NotebookExecutor()\ndf_DS_Lab_MySQL = nb.get_data('11561705035891145', '@SYS.USERID','False', {},['11561710911386024'])\ndf_DS_Lab_MySQL\n# The first function parameter refers to the service ID of the dataset.\n# @SYS.USERID refers to the user ID of the current user.\n# If the Sandbox key is 'false', it is referred to as a dataset, and if it's 'true', then the file is a sandbox file.\n# {} refers to the filters applied to the dataset.\n# [] refers to the data preparations applied to the dataset.\n# After [], users can specify the number of rows to limit the headcount of the dataset with a comma separator."]}, {"cell_type": "code", "execution_count": 3, "metadata": {"id": "1924798845_0.2198428668345671"}, "outputs": [{"ename": "Exception", "evalue": "'prepDetails'", "output_type": "error", "traceback": ["---------------------------------------------------------------------------", "Exception                                 Traceback (most recent call last)", "Cell In[4], line 3\n      1 from Notebook.DSNotebook.NotebookExecutor import NotebookExecutor\n      2 nb = NotebookExecutor()\n----> 3 df_DS_Oracle = nb.get_data('11561705559921354', '950278','False', {},['11561705565422191'])\n      4 df_DS_Oracle\n      5 # The first function parameter refers to the service ID of the dataset.\n      6 # 950278 refers to the user ID of the current user.\n      7 # If the Sandbox key is 'false', it is referred to as a dataset, and if it's 'true', then the file is a sandbox file.\n      8 # {} refers to the filters applied to the dataset.\n      9 # [] refers to the data preparations applied to the dataset.\n     10 # After [], users can specify the number of rows to limit the headcount of the dataset with a comma separator.\n", "File /app/Notebook/DSNotebook/NotebookExecutor.py:1628, in NotebookExecutor.get_data(self, serviceID, UserID, Sandbox, filters, prep_ids, limit, spark)\n   1626 except Exception as e:\n   1627     logging.error(f\"Error while readig data {serviceID} {str(e)}\")\n-> 1628     raise Exception(e) from None\n   1629 finally:\n   1630     os.chdir(f'{os.environ[\"DATASANDBOX_PATH\"]}/{os.environ[\"SPACE_KEY\"]}/{os.environ[\"PROJECT_ID\"]}')\n", "Exception: 'prepDetails'"]}], "source": ["from Notebook.DSNotebook.NotebookExecutor import NotebookExecutor\nnb = NotebookExecutor()\ndf_DS_Oracle = nb.get_data('11561705559921354', '@SYS.USERID','False', {},['11561705565422191'])\ndf_DS_Oracle\n# The first function parameter refers to the service ID of the dataset.\n# @SYS.USERID refers to the user ID of the current user.\n# If the Sandbox key is 'false', it is referred to as a dataset, and if it's 'true', then the file is a sandbox file.\n# {} refers to the filters applied to the dataset.\n# [] refers to the data preparations applied to the dataset.\n# After [], users can specify the number of rows to limit the headcount of the dataset with a comma separator."]}, {"cell_type": "code", "metadata": {"id": "25330371938_0.27653813065408084"}, "execution_count": 1, "source": ["from Notebook.DSNotebook.NotebookExecutor import NotebookExecutor\nnb = NotebookExecutor()\ndf_MultipleSheet_excel = nb.get_data('52311729836214233', '@SYS.USERID', 'True', {}, [], sheet_name = 'Sheet1')\n# The first function parameter refers to the service ID of the dataset.\n# @SYS.USERID refers to the user ID of the current user.\n# If the Sandbox key is 'false', it is referred to as a dataset, and if it's 'true', then the file is a sandbox file.\n# {} refers to the filters applied to the dataset.\n# [] refers to the data preparations applied to the dataset.\n# After [], users can specify the number of rows to limit the headcount of the dataset with a comma separator."], "outputs": []}], "metadata": {}, "nbformat": 4, "nbformat_minor": 2}