{"cells": [{"cell_type": "code", "metadata": {"id": "0_0.7875683182866644"}, "execution_count": null, "source": ["from Notebook.DSNotebook.NotebookExecutor import NotebookExecutor\nnb = NotebookExecutor()\ndf = nb.get_data('11561712724177662', '@SYS.USERID', 'True', {}, [])\ndf\n# The first function parameter refers to the service ID of the dataset.\n# @SYS.USERID refers to the user ID of the current user.\n# If the Sandbox key is 'false', it is referred to as a dataset, and if it's 'true', then the file is a sandbox file.\n# {} refers to the filters applied to the dataset.\n# [] refers to the data preparations applied to the dataset.\n# After [], users can specify the number of rows to limit the headcount of the dataset with a comma separator."], "outputs": []}, {"cell_type": "code", "metadata": {"id": "0_0.8826535993329667"}, "execution_count": null, "source": ["import pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\n\n# Initialize LabelEncoder\nencoder = LabelEncoder()\n\n# Fit and transform the column 'Category'\ndf['sex'] = encoder.fit_transform(df['sex'])\n\n# Optionally, replace the original column with the encoded values\n# df.drop('sex', axis=1, inplace=True)\n\n# Show the updated DataFrame\nprint(df)"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "0_0.22162569353514483"}, "execution_count": null, "source": ["import pandas as pd\nfrom time import perf_counter as get_time\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Define the necessary variables here\n_data   = df    # pd.DataFrame: Full data to process\n_target = 'sex'    # string: Column name of the target variable\n\nif _data is None or _target is None:\n    raise Exception(f'Both _data and _target must be specified')\nelif not (isinstance(_data, pd.DataFrame) and isinstance(_target, str)):\n    raise Exception(f'Datatype of _data must be pd.DataFrame; that of _target must be str')\n\n# Separating the independent and dependent variables into X and y respectively\ny = _data[_target]\nX = _data.drop(columns=_target)\nprint(f'Shape of complete data: {_data.shape}')\n\n# Splitting the dataset into training and testing datasets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\nprint(f'Shape of training data: {X_train.shape}')\nprint(f'Shape of testing data : {X_test.shape}')\n\n# Creating the classifier and fitting it to the training data\nlog_reg = LogisticRegression()\ntime_now = get_time()\nlog_reg.fit(X_train, y_train);\nprint(f'Model {log_reg} trained')\nprint(f'Seconds elapsed: {round(get_time() - time_now, 3)}')\n\n# Making predictions on the training data\npredict_train = log_reg.predict(X_train)\nprint(f'Predictions on training data made')\n\n# Finding the accuracy score of the training predictions\naccuracy_train = accuracy_score(y_train, predict_train)\nprint(f'Accuracy score of training predictions: {round(accuracy_train, 3)}')\n\n# Printing the classification report of the training predictions\nreport_train = classification_report(y_train, predict_train, digits=3)\nprint(f'Classification report of training predictions:')\nprint(report_train)\n\n# Making predictions on the testing data\npredict_test = log_reg.predict(X_test)\nprint(f'Predictions on testing data made')\n\n# Finding the accuracy score of the testing predictions\naccuracy_test = accuracy_score(y_test, predict_test)\nprint(f'Accuracy score of testing predictions: {round(accuracy_test, 3)}')\n\n# Printing the classification report of the testing predictions\nreport_test = classification_report(y_test, predict_test, digits=3)\nprint(f'Classification report of testing predictions:')\nprint(report_test)"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "0_0.36016780393124437"}, "execution_count": null, "source": ["from Notebook.DSNotebook.NotebookExecutor import NotebookExecutor\nnb = NotebookExecutor()\nsaved_model = nb.save_model(model = log_reg, modelName = 'Logistic_Regression_V3', modelType = 'ml', X = X_train, y = y_train, estimator_type='classification')\n#X and y are training datasets to get explainer dashboard.\n#estimator_type is to specify algorithm type i.e., classification and regression.\n#Only 'ml\u2019 models with tabular data as input will support in Explainer Dashboard.\n#Choose modelType = 'ml' for machine learning models, modelType = 'cv' for computer vision models and modelType = 'dp' for data transformation pickle files. \n#Provide \u2018column_headers\u2019 as a parameter if they have to be saved in the model.\n#If using custom layer in keras, use native save functionality from keras."], "outputs": []}], "metadata": {}, "nbformat": 4, "nbformat_minor": 2}