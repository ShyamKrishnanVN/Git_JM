{"autoML":null,"errorMessage":null,"errorCode":null,"notebookModels":null,"message":null,"notebookModel":null,"success":true,"notebooks":null,"messageCode":null,"stackTrace":null,"notebookContent":"{\"sucess\":true,\"content\":{\"cells\":[{\"cell_type\":\"code\",\"metadata\":{\"id\":\"5570611_0.678067885156864\"},\"execution_count\":0,\"source\":[\"from Notebook.DSNotebook.NotebookExecutor import NotebookExecutor\\nnb = NotebookExecutor()\\ndf = nb.get_data('11561697788370591', '@SYS.USERID', 'True', {}, [], None, sparkSession)\\ndf.show(10)\\n@ENV.MYSQL_DM_USERNAME   \\n@ENV.MYSQL_DM_PASSWORD\\n@ENV.MYSQL_DM_HTTP_PORT\\n@ENV.MYSQL_DM_HOST\"],\"outputs\":[{\"name\":\"stdout\",\"text\":[\"+-------------+--------+-----------+----------+----------+----------+--------+---------+------------+------+\\n|department_id|   email|employee_id|first_name| hire_date|    job_id|testnull|last_name|phone_number|salary|\\n+-------------+--------+-----------+----------+----------+----------+--------+---------+------------+------+\\n|           90|   SKING|       null|    Steven|13-01-1993|   AD_PRES|    null|     King|515.123.4567| 24000|\\n|           90|NKOCHHAR|       null|     Neena|14-01-1993|     AD_VP|    null|  Kochhar|515.123.4568| 17000|\\n|           90| LDEHAAN|        102|      Lex |13-01-1993|     AD_VP|    null|  De Haan|515.123.4569| 17000|\\n|           60| AHUNOLD|        103| Alexander|03-01-1990|   IT_PROG|    null|   Hunold|590.423.4567|  9000|\\n|           60|  BERNST|        104|     Bruce|21-05-1991|   IT_PROG|    null|    Ernst|590.423.4568|  6000|\\n|           60| DAUSTIN|        105|     David|25-06-1997|   IT_PROG|    null|   Austin|590.423.4569|  4800|\\n|           60|VPATABAL|        106|     Valli|05-02-1998|   IT_PROG|    null|Pataballa|590.423.4560|  4800|\\n|           60|DLORENTZ|        107|     Diana|07-02-1999|   IT_PROG|    null|  Lorentz|590.423.5567|  4200|\\n|          100|NGREENBE|        108|     Nancy|17-08-1994|    FI_MGR|    null|Greenberg|515.124.4569| 12000|\\n|          100| DFAVIET|        109|    Daniel|16-08-1994|FI_ACCOUNT|    null|   Faviet|515.124.4169|  9000|\\n+-------------+--------+-----------+----------+----------+----------+--------+---------+------------+------+\\nonly showing top 10 rows\\n\\n\"],\"output_type\":\"stream\"}]},{\"cell_type\":\"code\",\"metadata\":{\"id\":\"5570611_0.8005554017992687\"},\"execution_count\":1,\"source\":[\"@ENV.MYSQL_DM_USERNAME   \\n@ENV.MYSQL_DM_PASSWORD\\n@ENV.MYSQL_DM_HTTP_PORT\\n@ENV.MYSQL_DM_HOST\"],\"outputs\":[{\"data\":{\"text/plain\":\"'@ENV.MYSQL_DM_HOST'\"},\"metadata\":{},\"execution_count\":2,\"output_type\":\"execute_result\"}]},{\"cell_type\":\"code\",\"metadata\":{\"id\":\"5570611_0.36668263008588875\"},\"execution_count\":3,\"source\":[\"def pyspark_write(df, table, user, password, host, port, database):\\n    \\\"\\\"\\\"\\n    Write a PySpark DataFrame to a MySQL database using JDBC.\\n\\n    Args:\\n        df (pyspark.sql.DataFrame): DataFrame to write.\\n        table (str): Name of the table to write to.\\n        user (str): Username to authenticate with.\\n        password (str): Password to authenticate with.\\n        host (str): Hostname or IP address of the MySQL server.\\n        port (int): Port number of the MySQL server.\\n        database (str): Name of the MySQL database to use.\\n    \\\"\\\"\\\"\\n    try:\\n        url = \\\"jdbc:mysql://\\\"+host+\\\":\\\"+str(port)+\\\"/\\\"+database\\n        # uncomment below lines if dataframe size is big \\n        # numPartitions = 8\\n        # df = df.repartition(numPartitions)\\n        df.write \\\\\\n            .format(\\\"jdbc\\\") \\\\\\n            .option(\\\"url\\\", url) \\\\\\n            .option(\\\"driver\\\", \\\"com.mysql.cj.jdbc.Driver\\\") \\\\\\n            .option(\\\"dbtable\\\", table) \\\\\\n            .option(\\\"user\\\", user) \\\\\\n            .option(\\\"password\\\", password) \\\\\\n            .mode(\\\"overwrite\\\") \\\\\\n            .save()\\n        print(\\\"Saved Successfully\\\")\\n    except Exception as e:\\n        print(e)\\n\\npyspark_write(df=df, table=\\\"PySpark_Dumps\\\", user=@ENV.MYSQL_DM_USERNAME, password=@ENV.MYSQL_DM_PASSWORD, host=@ENV.MYSQL_DM_HOST, port=@ENV.MYSQL_DM_HTTP_PORT, database=\\\"qa_test\\\")\"],\"outputs\":[{\"name\":\"stdout\",\"text\":[\"Saved Successfully\\n\"],\"output_type\":\"stream\"}]}],\"metadata\":{},\"nbformat\":4,\"nbformat_minor\":2}}","autoMLs":null,"notebook":{"updatedBy":950278,"data":"{\"datasets\":[{\"queryservicename\":\"Test\",\"id\":4063367,\"type\":\"Data Sandbox\",\"uuid\":\"11561697788370591\",\"extenstion\":\"csv\",\"fileType\":\"\",\"isSelected\":true}],\"uncheckeddatasets\":[],\"code\":[{\"id\":\"5570611_0.678067885156864\",\"code\":\"from Notebook.DSNotebook.NotebookExecutor import NotebookExecutor\\nnb = NotebookExecutor()\\ndf = nb.get_data('11561697788370591', '@SYS.USERID', 'True', {}, [], None, sparkSession)\\ndf.show(10)\\n@ENV.MYSQL_DM_USERNAME   \\n@ENV.MYSQL_DM_PASSWORD\\n@ENV.MYSQL_DM_HTTP_PORT\\n@ENV.MYSQL_DM_HOST\",\"count\":4,\"mode\":\"preview\",\"type\":\"code\",\"hover\":true,\"interrupt\":false,\"warning\":false,\"outputArray\":\"\",\"lineNumber\":false,\"laodmodel\":false,\"pre_cell_id\":0,\"is_pre_cell\":false,\"succORerr\":true,\"expand\":false,\"outputexpand\":false,\"readonly\":false,\"markDowns\":false,\"loader\":false,\"image\":\"\",\"error\":\"\",\"result\":\"\",\"algorithms\":\"\",\"semicolon\":\"\",\"cputimes\":\"\",\"showcputime\":true,\"secret\":[\"@ENV.MYSQL_DM_USERNAME   \",\"@ENV.MYSQL_DM_PASSWORD\",\"@ENV.MYSQL_DM_HTTP_PORT\",\"@ENV.MYSQL_DM_HOST\"],\"widget\":false},{\"id\":\"5570611_0.8005554017992687\",\"code\":\"@ENV.MYSQL_DM_USERNAME   \\n@ENV.MYSQL_DM_PASSWORD\\n@ENV.MYSQL_DM_HTTP_PORT\\n@ENV.MYSQL_DM_HOST\",\"count\":5,\"mode\":\"preview\",\"type\":\"code\",\"hover\":true,\"interrupt\":false,\"warning\":false,\"outputArray\":\"\",\"lineNumber\":false,\"laodmodel\":false,\"pre_cell_id\":0,\"is_pre_cell\":false,\"succORerr\":true,\"expand\":false,\"outputexpand\":false,\"readonly\":false,\"markDowns\":false,\"loader\":false,\"image\":\"\",\"error\":\"\",\"result\":\"\",\"algorithms\":\"\",\"semicolon\":\"\",\"cputimes\":\"\",\"showcputime\":true,\"secret\":[],\"widget\":false},{\"id\":\"5570611_0.36668263008588875\",\"code\":\"def pyspark_write(df, table, user, password, host, port, database):\\n    \\\"\\\"\\\"\\n    Write a PySpark DataFrame to a MySQL database using JDBC.\\n\\n    Args:\\n        df (pyspark.sql.DataFrame): DataFrame to write.\\n        table (str): Name of the table to write to.\\n        user (str): Username to authenticate with.\\n        password (str): Password to authenticate with.\\n        host (str): Hostname or IP address of the MySQL server.\\n        port (int): Port number of the MySQL server.\\n        database (str): Name of the MySQL database to use.\\n    \\\"\\\"\\\"\\n    try:\\n        url = \\\"jdbc:mysql://\\\"+host+\\\":\\\"+str(port)+\\\"/\\\"+database\\n        # uncomment below lines if dataframe size is big \\n        # numPartitions = 8\\n        # df = df.repartition(numPartitions)\\n        df.write \\\\\\n            .format(\\\"jdbc\\\") \\\\\\n            .option(\\\"url\\\", url) \\\\\\n            .option(\\\"driver\\\", \\\"com.mysql.cj.jdbc.Driver\\\") \\\\\\n            .option(\\\"dbtable\\\", table) \\\\\\n            .option(\\\"user\\\", user) \\\\\\n            .option(\\\"password\\\", password) \\\\\\n            .mode(\\\"overwrite\\\") \\\\\\n            .save()\\n        print(\\\"Saved Successfully\\\")\\n    except Exception as e:\\n        print(e)\\n\\npyspark_write(df=df, table=\\\"PySpark_Dumps\\\", user=@ENV.MYSQL_DM_USERNAME, password=@ENV.MYSQL_DM_PASSWORD, host=@ENV.MYSQL_DM_HOST, port=@ENV.MYSQL_DM_HTTP_PORT, database=\\\"qa_test\\\")\",\"count\":3,\"mode\":\"preview\",\"type\":\"code\",\"hover\":true,\"interrupt\":false,\"warning\":false,\"outputArray\":[],\"lineNumber\":false,\"laodmodel\":false,\"pre_cell_id\":0,\"is_pre_cell\":false,\"succORerr\":true,\"expand\":false,\"outputexpand\":false,\"readonly\":false,\"markDowns\":false,\"loader\":false,\"image\":\"\",\"error\":\"\",\"result\":\"\",\"algorithms\":\"\",\"semicolon\":\"\",\"cputimes\":\"\",\"showcputime\":false,\"secret\":[]}],\"kernalID\":\"56db17a4-be73-4c77-8dfe-985a81662e43\",\"Algorithms\":[],\"isScheduled\":0,\"last_modified_date\":\"\"}","isImported":0,"customComponentscript":"{\"DSLAB_content\":\"[]\",\"pipeline_content\":\"\\\"\\\"\",\"externalLibraries\":\"[]\"}","description":null,"lastcommittedDate":1697804447368,"isScheduled":1,"committedBy":950278,"type":2,"uuid":"11561697804447378","spaceKey":"1156","migrationId":null,"path":null,"lastUpdatedDate":1700223436664,"createdDate":1697804447368,"createdBy":950278,"notebookName":"PySpark_Sample Note","id":5570611,"projectId":1474562,"isShared":null,"status":1}}