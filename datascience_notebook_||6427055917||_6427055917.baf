{"featureSets":null,"autoML":null,"superFeatureSet":null,"errorMessage":null,"featureSet":null,"errorCode":null,"notebookModels":null,"message":"Successfully retrived!","notebookModelAsApi":null,"notebookModel":null,"notebookModelAsApis":null,"success":true,"notebooks":null,"customNotebookScript":null,"superFeatureSets":null,"messageCode":null,"stackTrace":null,"notebookContent":"{\"sucess\":true,\"content\":{\"cells\":[{\"cell_type\":\"code\",\"metadata\":{\"id\":\"0_0.1783835660386166\"},\"execution_count\":null,\"source\":[\"def e_s():   \\n    from Notebook.DSNotebook.NotebookExecutor import NotebookExecutor \\n    nb = NotebookExecutor()\\n    df_HiringData = nb.get_data('11111718769832496', '@SYS.USERID', 'True', {}, [])\\n    return df_HiringData\"],\"outputs\":[]},{\"cell_type\":\"code\",\"metadata\":{\"id\":\"6427055917_0.5307330970938233\"},\"execution_count\":null,\"source\":[\"from Notebook.DSNotebook.NotebookExecutor import NotebookExecutor\\nnb = NotebookExecutor()\\ndf_Demo_2 = nb.get_data('11111721718340006', '@SYS.USERID', 'False', {}, [], None, None, version = 1)\\ndf_Demo_2\\n# The first function parameter refers to the service ID of the dataset.\\n# @SYS.USERID refers to the user ID of the current user.\\n# If the Sandbox key is 'false', it is referred to as a dataset, and if it's 'true', then the file is a sandbox file.\\n# {} refers to the filters applied to the dataset.\\n# [] refers to the data preparations applied to the dataset.\\n# After [], users can specify the number of rows to limit the headcount of the dataset with a comma separator.\\n# The last function parameter indicates the Feature Store version.\"],\"outputs\":[]},{\"cell_type\":\"code\",\"metadata\":{\"id\":\"6427055917_0.0073208827995512316\"},\"execution_count\":null,\"source\":[\"from Notebook.DSNotebook.NotebookExecutor import NotebookExecutor\\nnb = NotebookExecutor()\\ndf_Demo_1 = nb.get_data('11111721718130252', '@SYS.USERID', 'False', {}, [], None, None, version = 1)\\ndf_Demo_1\\n# The first function parameter refers to the service ID of the dataset.\\n# @SYS.USERID refers to the user ID of the current user.\\n# If the Sandbox key is 'false', it is referred to as a dataset, and if it's 'true', then the file is a sandbox file.\\n# {} refers to the filters applied to the dataset.\\n# [] refers to the data preparations applied to the dataset.\\n# After [], users can specify the number of rows to limit the headcount of the dataset with a comma separator.\\n# The last function parameter indicates the Feature Store version.\"],\"outputs\":[]},{\"cell_type\":\"code\",\"metadata\":{\"id\":\"6427055917_0.2925146334875173\"},\"execution_count\":null,\"source\":[\"with open('/app/requirements.txt', 'r') as file:\\n    required_packages = {line.split('==')[0] for line in file if '==' in line}\\n\\n# Get the current pip freeze output\\ninstalled_packages = !pip freeze\\n\\n# Filter the installed packages to include only those in requirements.txt\\nfiltered_packages = [pkg for pkg in installed_packages if pkg.split('==')[0] in required_packages]\\n\\n# Print the filtered packages\\nfor pkg in required_packages:\\n    print(pkg)\\n\"],\"outputs\":[]},{\"cell_type\":\"code\",\"metadata\":{\"id\":\"6427055917_0.18096662640644823\"},\"execution_count\":null,\"source\":[\"import pickle, os\\n\\n# Display the installed packages and their versions\\n!pip freeze\\n\\n# Save the installed packages and their versions to requirements.txt\\n!pip freeze > requirements.txt\\n\\n# Read and display the content of requirements.txt to verify\\nwith open('/app/requirements.txt', 'r') as file:\\n    content = file.read()\\n    print(content)\\n\"],\"outputs\":[]},{\"cell_type\":\"code\",\"metadata\":{\"id\":\"6427055917_0.8163912043875838\"},\"execution_count\":null,\"source\":[\"# Save the list of installed packages and their versions to requirements.txt\\n!pip freeze > requirements.txt\\n\\n# Display the content of requirements.txt to verify\\nwith open('/app/requirements.txt', 'r') as file:\\n    content = file.read()\\n    print(content)\\n\"],\"outputs\":[]},{\"cell_type\":\"code\",\"metadata\":{\"id\":\"6427055917_0.4935612023525009\"},\"execution_count\":null,\"source\":[\"def get_library_versions(requirements_file):\\n    with open(requirements_file, 'r') as file:\\n        lines = file.readlines()\\n        for line in lines:\\n            line = line.strip()\\n            if '==' in line:\\n                library, version = line.split('==')\\n                print(f\\\"{library}: {version}\\\")\\n            else:\\n                print(f\\\"{line}: Version not specified\\\")\\n\\n# Example usage\\nget_library_versions('/app/requirements.txt')\\n\"],\"outputs\":[]},{\"cell_type\":\"code\",\"metadata\":{\"id\":\"6427055917_0.664915371947411\"},\"execution_count\":1,\"source\":[\"import pandas\"],\"outputs\":[]},{\"cell_type\":\"code\",\"metadata\":{\"id\":\"6427055917_0.6115525509903201\"},\"execution_count\":null,\"source\":[\"import re\\n\\ndef read_file(file_path):\\n    with open(file_path, 'r') as file:\\n        content = file.read()\\n    return content\\n\\ndef extract_libraries(text):\\n    # Use regular expression to extract library and version pairs\\n    libraries = re.findall(r'(\\\\S+)==(\\\\S+)', text)\\n    return dict(libraries)\\n\\ndef find_similar_libraries(file1, file2):\\n    text1 = read_file(file1)\\n    text2 = read_file(file2)\\n    \\n    libraries1 = extract_libraries(text1)\\n    libraries2 = extract_libraries(text2)\\n    \\n    # Find common libraries and their versions\\n    similar_libraries = {lib: version for lib, version in libraries1.items() if lib in libraries2 and libraries2[lib] == version}\\n    \\n    return similar_libraries\\n\\n# File paths\\nfile1 = @SYS.DATASANDBOX_PATH + '133093444/Data/tensorflow_requirements.txt'\\nfile2 = @SYS.DATASANDBOX_PATH + '133093444/Data/pip_freeze_requirements.txt'\\n\\n# Find and print similar libraries with versions\\nsimilar_libraries = find_similar_libraries(file1, file2)\\nprint(\\\"Similar libraries with versions:\\\", similar_libraries)\\n\"],\"outputs\":[]},{\"cell_type\":\"code\",\"metadata\":{\"id\":\"6427055917_0.23153220725184043\"},\"execution_count\":1,\"source\":[\"from Notebook.DSNotebook.NotebookExecutor import NotebookExecutor\\nnb = NotebookExecutor()\\ndf_Limrick = nb.get_data('11111718361596235', '@SYS.USERID', 'True', {}, [])\\ndf_Limrick\"],\"outputs\":[{\"data\":{\"text/plain\":[\"          date  Machine  Mcode  Shift DowntimeDesctiption  DD  DowntimeInHours\\n0   2021-06-01   901850      1      1                Idle   2         0.850278\\n1   2021-06-01   901850      1      1               Setup   3         0.000556\\n2   2021-06-01   901850      1      2                Idle   2         1.929167\\n3   2021-06-01   901850      1      2               Setup   3         0.034167\\n4   2021-06-01   901850      1      3                Idle   2         3.436389\\n..         ...      ...    ...    ...                 ...  ..              ...\\n277 2021-06-28   903030      2      2               Setup   3         0.002778\\n278 2021-06-29   901850      1      1                Idle   2         1.397222\\n279 2021-06-29   901850      1      1               Setup   3         0.001389\\n280 2021-06-29   903030      2      1                Idle   2         0.188889\\n281 2021-06-29   903030      2      1               Setup   3         0.005556\\n\\n[282 rows x 7 columns]\"],\"text/html\":[\"<div>\\n<style scoped>\\n    .dataframe tbody tr th:only-of-type {\\n        vertical-align: middle;\\n    }\\n\\n    .dataframe tbody tr th {\\n        vertical-align: top;\\n    }\\n\\n    .dataframe thead th {\\n        text-align: right;\\n    }\\n<\/style>\\n<table border=\\\"1\\\" class=\\\"dataframe\\\">\\n  <thead>\\n    <tr style=\\\"text-align: right;\\\">\\n      <th><\/th>\\n      <th>date<\/th>\\n      <th>Machine<\/th>\\n      <th>Mcode<\/th>\\n      <th>Shift<\/th>\\n      <th>DowntimeDesctiption<\/th>\\n      <th>DD<\/th>\\n      <th>DowntimeInHours<\/th>\\n    <\/tr>\\n  <\/thead>\\n  <tbody>\\n    <tr>\\n      <th>0<\/th>\\n      <td>2021-06-01<\/td>\\n      <td>901850<\/td>\\n      <td>1<\/td>\\n      <td>1<\/td>\\n      <td>Idle<\/td>\\n      <td>2<\/td>\\n      <td>0.850278<\/td>\\n    <\/tr>\\n    <tr>\\n      <th>1<\/th>\\n      <td>2021-06-01<\/td>\\n      <td>901850<\/td>\\n      <td>1<\/td>\\n      <td>1<\/td>\\n      <td>Setup<\/td>\\n      <td>3<\/td>\\n      <td>0.000556<\/td>\\n    <\/tr>\\n    <tr>\\n      <th>2<\/th>\\n      <td>2021-06-01<\/td>\\n      <td>901850<\/td>\\n      <td>1<\/td>\\n      <td>2<\/td>\\n      <td>Idle<\/td>\\n      <td>2<\/td>\\n      <td>1.929167<\/td>\\n    <\/tr>\\n    <tr>\\n      <th>3<\/th>\\n      <td>2021-06-01<\/td>\\n      <td>901850<\/td>\\n      <td>1<\/td>\\n      <td>2<\/td>\\n      <td>Setup<\/td>\\n      <td>3<\/td>\\n      <td>0.034167<\/td>\\n    <\/tr>\\n    <tr>\\n      <th>4<\/th>\\n      <td>2021-06-01<\/td>\\n      <td>901850<\/td>\\n      <td>1<\/td>\\n      <td>3<\/td>\\n      <td>Idle<\/td>\\n      <td>2<\/td>\\n      <td>3.436389<\/td>\\n    <\/tr>\\n    <tr>\\n      <th>...<\/th>\\n      <td>...<\/td>\\n      <td>...<\/td>\\n      <td>...<\/td>\\n      <td>...<\/td>\\n      <td>...<\/td>\\n      <td>...<\/td>\\n      <td>...<\/td>\\n    <\/tr>\\n    <tr>\\n      <th>277<\/th>\\n      <td>2021-06-28<\/td>\\n      <td>903030<\/td>\\n      <td>2<\/td>\\n      <td>2<\/td>\\n      <td>Setup<\/td>\\n      <td>3<\/td>\\n      <td>0.002778<\/td>\\n    <\/tr>\\n    <tr>\\n      <th>278<\/th>\\n      <td>2021-06-29<\/td>\\n      <td>901850<\/td>\\n      <td>1<\/td>\\n      <td>1<\/td>\\n      <td>Idle<\/td>\\n      <td>2<\/td>\\n      <td>1.397222<\/td>\\n    <\/tr>\\n    <tr>\\n      <th>279<\/th>\\n      <td>2021-06-29<\/td>\\n      <td>901850<\/td>\\n      <td>1<\/td>\\n      <td>1<\/td>\\n      <td>Setup<\/td>\\n      <td>3<\/td>\\n      <td>0.001389<\/td>\\n    <\/tr>\\n    <tr>\\n      <th>280<\/th>\\n      <td>2021-06-29<\/td>\\n      <td>903030<\/td>\\n      <td>2<\/td>\\n      <td>1<\/td>\\n      <td>Idle<\/td>\\n      <td>2<\/td>\\n      <td>0.188889<\/td>\\n    <\/tr>\\n    <tr>\\n      <th>281<\/th>\\n      <td>2021-06-29<\/td>\\n      <td>903030<\/td>\\n      <td>2<\/td>\\n      <td>1<\/td>\\n      <td>Setup<\/td>\\n      <td>3<\/td>\\n      <td>0.005556<\/td>\\n    <\/tr>\\n  <\/tbody>\\n<\/table>\\n<p>282 rows × 7 columns<\/p>\\n<\/div>\"]},\"metadata\":{},\"execution_count\":2,\"output_type\":\"execute_result\"}]},{\"cell_type\":\"code\",\"metadata\":{\"id\":\"6427055917_0.5703367622287141\"},\"execution_count\":5,\"source\":[\"df_Limrick.info()\"],\"outputs\":[{\"name\":\"stdout\",\"text\":[\"<class 'pandas.core.frame.DataFrame'>\\nRangeIndex: 282 entries, 0 to 281\\nData columns (total 7 columns):\\n #   Column               Non-Null Count  Dtype         \\n---  ------               --------------  -----         \\n 0   date                 282 non-null    datetime64[ns]\\n 1   Machine              282 non-null    int64         \\n 2   Mcode                282 non-null    int64         \\n 3   Shift                282 non-null    int64         \\n 4   DowntimeDesctiption  282 non-null    object        \\n 5   DD                   282 non-null    int64         \\n 6   DowntimeInHours      282 non-null    float64       \\ndtypes: datetime64[ns](1), float64(1), int64(4), object(1)\\nmemory usage: 15.5+ KB\\n\"],\"output_type\":\"stream\"}]},{\"cell_type\":\"code\",\"metadata\":{\"id\":\"6427055917_0.9575873512745192\"},\"execution_count\":4,\"source\":[\"from Notebook.DSNotebook.NotebookExecutor import NotebookExecutor\\nnb = NotebookExecutor()\\nnb.mssql_writer('shyam', 'Shy@8746dd8i23', 'bdbcirclek.c9lo3db08qkg.ap-south-1.rds.amazonaws.com', '1433', 'dslabtest', 'Limrick_data', df_Limrick)\"],\"outputs\":[{\"name\":\"stdout\",\"text\":[\"Dataframe has been written to database.\\n\"],\"output_type\":\"stream\"}]},{\"cell_type\":\"code\",\"metadata\":{\"id\":\"6427055917_0.8354684183551644\"},\"execution_count\":null,\"source\":[\"from Notebook.DSNotebook.NotebookExecutor import NotebookExecutor\\nnb = NotebookExecutor()\\nnb.clickhouse_writer('username', 'password', 'host', 'port', 'database', 'tablename', df)\"],\"outputs\":[]}],\"metadata\":{},\"nbformat\":4,\"nbformat_minor\":2}}","bizvizNotebook":null,"autoMLs":null,"scripts":null,"bizvizNotebooks":null,"notebook":{"mongoQL":null,"updatedBy":524290,"data":"{\"datasets\":[{\"id\":6817146766,\"uuid\":\"11111721718340006\",\"createdDate\":1721718333446,\"dataSourceType\":\"mssql\",\"type\":\"Feature Store\",\"queryservicename\":\"Demo_2\",\"version\":\"1\",\"superFeatureSetId\":6817145747,\"isSelected\":true},{\"id\":6816395711,\"uuid\":\"11111721718130252\",\"createdDate\":1721718079027,\"dataSourceType\":\"mssql\",\"type\":\"Feature Store\",\"queryservicename\":\"Demo_1\",\"version\":\"1\",\"superFeatureSetId\":6816394692,\"isSelected\":true},{\"queryservicename\":\"HiringData\",\"id\":692010996,\"type\":\"Data Sandbox\",\"uuid\":\"11111718769832496\",\"extenstion\":\"csv\",\"fileType\":\"\",\"dataSourceType\":\"csv\",\"createdDate\":1718769832000,\"isSelected\":true},{\"queryservicename\":\"Limrick\",\"id\":392502750,\"type\":\"Data Sandbox\",\"uuid\":\"11111718361596235\",\"extenstion\":\"xlsx\",\"fileType\":\"\",\"dataSourceType\":\"xlsx\",\"createdDate\":1718361596000,\"isSelected\":true}],\"uncheckeddatasets\":[],\"code\":[{\"id\":\"0_0.1783835660386166\",\"conflict\":\"false\",\"code\":\"def e_s():   \\n    from Notebook.DSNotebook.NotebookExecutor import NotebookExecutor \\n    nb = NotebookExecutor()\\n    df_HiringData = nb.get_data('11111718769832496', '@SYS.USERID', 'True', {}, [])\\n    return df_HiringData\",\"count\":1,\"mode\":\"preview\",\"type\":\"code\",\"hover\":true,\"interrupt\":false,\"warning\":false,\"outputArray\":[],\"lineNumber\":false,\"laodmodel\":false,\"pre_cell_id\":0,\"is_pre_cell\":false,\"succORerr\":true,\"expand\":false,\"outputexpand\":false,\"readonly\":false,\"markDowns\":false,\"loader\":false,\"image\":\"\",\"error\":\"\",\"result\":\"\",\"algorithms\":\"\",\"semicolon\":\"\",\"cputimes\":\"\",\"showcputime\":false,\"secret\":[]},{\"id\":\"6427055917_0.5307330970938233\",\"conflict\":\"false\",\"code\":\"from Notebook.DSNotebook.NotebookExecutor import NotebookExecutor\\nnb = NotebookExecutor()\\ndf_Demo_2 = nb.get_data('11111721718340006', '@SYS.USERID', 'False', {}, [], None, None, version = 1)\\ndf_Demo_2\\n# The first function parameter refers to the service ID of the dataset.\\n# @SYS.USERID refers to the user ID of the current user.\\n# If the Sandbox key is 'false', it is referred to as a dataset, and if it's 'true', then the file is a sandbox file.\\n# {} refers to the filters applied to the dataset.\\n# [] refers to the data preparations applied to the dataset.\\n# After [], users can specify the number of rows to limit the headcount of the dataset with a comma separator.\\n# The last function parameter indicates the Feature Store version.\",\"count\":2,\"mode\":\"preview\",\"type\":\"code\",\"hover\":true,\"interrupt\":false,\"warning\":false,\"outputArray\":[],\"lineNumber\":false,\"laodmodel\":false,\"pre_cell_id\":0,\"is_pre_cell\":false,\"succORerr\":true,\"expand\":false,\"outputexpand\":false,\"readonly\":false,\"markDowns\":false,\"loader\":false,\"image\":\"\",\"error\":\"\",\"result\":\"\",\"algorithms\":\"\",\"semicolon\":\"\",\"cputimes\":\"\",\"showcputime\":false,\"secret\":[]},{\"id\":\"6427055917_0.0073208827995512316\",\"conflict\":\"false\",\"code\":\"from Notebook.DSNotebook.NotebookExecutor import NotebookExecutor\\nnb = NotebookExecutor()\\ndf_Demo_1 = nb.get_data('11111721718130252', '@SYS.USERID', 'False', {}, [], None, None, version = 1)\\ndf_Demo_1\\n# The first function parameter refers to the service ID of the dataset.\\n# @SYS.USERID refers to the user ID of the current user.\\n# If the Sandbox key is 'false', it is referred to as a dataset, and if it's 'true', then the file is a sandbox file.\\n# {} refers to the filters applied to the dataset.\\n# [] refers to the data preparations applied to the dataset.\\n# After [], users can specify the number of rows to limit the headcount of the dataset with a comma separator.\\n# The last function parameter indicates the Feature Store version.\",\"count\":3,\"mode\":\"preview\",\"type\":\"code\",\"hover\":true,\"interrupt\":false,\"warning\":false,\"outputArray\":[],\"lineNumber\":false,\"laodmodel\":false,\"pre_cell_id\":0,\"is_pre_cell\":false,\"succORerr\":true,\"expand\":false,\"outputexpand\":false,\"readonly\":false,\"markDowns\":false,\"loader\":false,\"image\":\"\",\"error\":\"\",\"result\":\"\",\"algorithms\":\"\",\"semicolon\":\"\",\"cputimes\":\"\",\"showcputime\":false,\"secret\":[]},{\"id\":\"6427055917_0.2925146334875173\",\"conflict\":\"false\",\"code\":\"with open('/app/requirements.txt', 'r') as file:\\n    required_packages = {line.split('==')[0] for line in file if '==' in line}\\n\\n# Get the current pip freeze output\\ninstalled_packages = !pip freeze\\n\\n# Filter the installed packages to include only those in requirements.txt\\nfiltered_packages = [pkg for pkg in installed_packages if pkg.split('==')[0] in required_packages]\\n\\n# Print the filtered packages\\nfor pkg in required_packages:\\n    print(pkg)\\n\",\"count\":4,\"mode\":\"preview\",\"type\":\"code\",\"hover\":true,\"interrupt\":false,\"warning\":false,\"outputArray\":[],\"lineNumber\":false,\"laodmodel\":false,\"pre_cell_id\":0,\"is_pre_cell\":false,\"succORerr\":true,\"expand\":false,\"outputexpand\":false,\"readonly\":false,\"markDowns\":false,\"loader\":false,\"image\":\"\",\"error\":\"\",\"result\":\"\",\"algorithms\":\"\",\"semicolon\":\"\",\"cputimes\":\"\",\"showcputime\":false,\"secret\":[]},{\"id\":\"6427055917_0.18096662640644823\",\"conflict\":\"false\",\"code\":\"import pickle, os\\n\\n# Display the installed packages and their versions\\n!pip freeze\\n\\n# Save the installed packages and their versions to requirements.txt\\n!pip freeze > requirements.txt\\n\\n# Read and display the content of requirements.txt to verify\\nwith open('/app/requirements.txt', 'r') as file:\\n    content = file.read()\\n    print(content)\\n\",\"count\":5,\"mode\":\"preview\",\"type\":\"code\",\"hover\":true,\"interrupt\":false,\"warning\":false,\"outputArray\":[],\"lineNumber\":false,\"laodmodel\":false,\"pre_cell_id\":0,\"is_pre_cell\":false,\"succORerr\":true,\"expand\":false,\"outputexpand\":false,\"readonly\":false,\"markDowns\":false,\"loader\":false,\"image\":\"\",\"error\":\"\",\"result\":\"\",\"algorithms\":\"\",\"semicolon\":\"\",\"cputimes\":\"\",\"showcputime\":false,\"secret\":[]},{\"id\":\"6427055917_0.8163912043875838\",\"conflict\":\"false\",\"code\":\"# Save the list of installed packages and their versions to requirements.txt\\n!pip freeze > requirements.txt\\n\\n# Display the content of requirements.txt to verify\\nwith open('/app/requirements.txt', 'r') as file:\\n    content = file.read()\\n    print(content)\\n\",\"count\":6,\"mode\":\"preview\",\"type\":\"code\",\"hover\":true,\"interrupt\":false,\"warning\":false,\"outputArray\":[],\"lineNumber\":false,\"laodmodel\":false,\"pre_cell_id\":0,\"is_pre_cell\":false,\"succORerr\":true,\"expand\":false,\"outputexpand\":false,\"readonly\":false,\"markDowns\":false,\"loader\":false,\"image\":\"\",\"error\":\"\",\"result\":\"\",\"algorithms\":\"\",\"semicolon\":\"\",\"cputimes\":\"\",\"showcputime\":false,\"secret\":[]},{\"id\":\"6427055917_0.4935612023525009\",\"conflict\":\"false\",\"code\":\"def get_library_versions(requirements_file):\\n    with open(requirements_file, 'r') as file:\\n        lines = file.readlines()\\n        for line in lines:\\n            line = line.strip()\\n            if '==' in line:\\n                library, version = line.split('==')\\n                print(f\\\"{library}: {version}\\\")\\n            else:\\n                print(f\\\"{line}: Version not specified\\\")\\n\\n# Example usage\\nget_library_versions('/app/requirements.txt')\\n\",\"count\":7,\"mode\":\"preview\",\"type\":\"code\",\"hover\":true,\"interrupt\":false,\"warning\":false,\"outputArray\":[],\"lineNumber\":false,\"laodmodel\":false,\"pre_cell_id\":0,\"is_pre_cell\":false,\"succORerr\":true,\"expand\":false,\"outputexpand\":false,\"readonly\":false,\"markDowns\":false,\"loader\":false,\"image\":\"\",\"error\":\"\",\"result\":\"\",\"algorithms\":\"\",\"semicolon\":\"\",\"cputimes\":\"\",\"showcputime\":false,\"secret\":[]},{\"id\":\"6427055917_0.664915371947411\",\"pre_cell_id\":\"6427055917_0.4935612023525009\",\"is_pre_cell\":true,\"succORerr\":true,\"type\":\"code\",\"code\":\"import pandas\",\"count\":13,\"mode\":\"editor\",\"result\":\"\",\"outputArray\":\"\",\"image\":\"\",\"error\":\"\",\"hover\":true,\"interrupt\":false,\"warning\":false,\"lineNumber\":false,\"laodmodel\":false,\"loader\":false,\"expand\":false,\"outputexpand\":false,\"readonly\":false,\"secret\":[],\"markDowns\":false,\"widget\":false,\"showcputime\":true},{\"id\":\"6427055917_0.6115525509903201\",\"conflict\":\"false\",\"code\":\"import re\\n\\ndef read_file(file_path):\\n    with open(file_path, 'r') as file:\\n        content = file.read()\\n    return content\\n\\ndef extract_libraries(text):\\n    # Use regular expression to extract library and version pairs\\n    libraries = re.findall(r'(\\\\S+)==(\\\\S+)', text)\\n    return dict(libraries)\\n\\ndef find_similar_libraries(file1, file2):\\n    text1 = read_file(file1)\\n    text2 = read_file(file2)\\n    \\n    libraries1 = extract_libraries(text1)\\n    libraries2 = extract_libraries(text2)\\n    \\n    # Find common libraries and their versions\\n    similar_libraries = {lib: version for lib, version in libraries1.items() if lib in libraries2 and libraries2[lib] == version}\\n    \\n    return similar_libraries\\n\\n# File paths\\nfile1 = @SYS.DATASANDBOX_PATH + '133093444/Data/tensorflow_requirements.txt'\\nfile2 = @SYS.DATASANDBOX_PATH + '133093444/Data/pip_freeze_requirements.txt'\\n\\n# Find and print similar libraries with versions\\nsimilar_libraries = find_similar_libraries(file1, file2)\\nprint(\\\"Similar libraries with versions:\\\", similar_libraries)\\n\",\"count\":8,\"mode\":\"preview\",\"type\":\"code\",\"hover\":true,\"interrupt\":false,\"warning\":false,\"outputArray\":[],\"lineNumber\":false,\"laodmodel\":false,\"pre_cell_id\":0,\"is_pre_cell\":false,\"succORerr\":true,\"expand\":false,\"outputexpand\":false,\"readonly\":false,\"markDowns\":false,\"loader\":false,\"image\":\"\",\"error\":\"\",\"result\":\"\",\"algorithms\":\"\",\"semicolon\":\"\",\"cputimes\":\"\",\"showcputime\":false,\"secret\":[]},{\"id\":\"6427055917_0.23153220725184043\",\"conflict\":\"false\",\"code\":\"from Notebook.DSNotebook.NotebookExecutor import NotebookExecutor\\nnb = NotebookExecutor()\\ndf_Limrick = nb.get_data('11111718361596235', '@SYS.USERID', 'True', {}, [])\\ndf_Limrick\",\"count\":9,\"mode\":\"preview\",\"type\":\"code\",\"hover\":true,\"interrupt\":false,\"warning\":false,\"outputArray\":[],\"lineNumber\":false,\"laodmodel\":false,\"pre_cell_id\":0,\"is_pre_cell\":false,\"succORerr\":true,\"expand\":false,\"outputexpand\":false,\"readonly\":false,\"markDowns\":false,\"loader\":false,\"image\":\"\",\"error\":\"\",\"result\":\"\",\"algorithms\":\"\",\"semicolon\":\"\",\"cputimes\":\"\",\"showcputime\":false,\"secret\":[]},{\"id\":\"6427055917_0.5703367622287141\",\"conflict\":\"false\",\"code\":\"df_Limrick.info()\",\"count\":10,\"mode\":\"preview\",\"type\":\"code\",\"hover\":true,\"interrupt\":false,\"warning\":false,\"outputArray\":[],\"lineNumber\":false,\"laodmodel\":false,\"pre_cell_id\":0,\"is_pre_cell\":false,\"succORerr\":true,\"expand\":false,\"outputexpand\":false,\"readonly\":false,\"markDowns\":false,\"loader\":false,\"image\":\"\",\"error\":\"\",\"result\":\"\",\"algorithms\":\"\",\"semicolon\":\"\",\"cputimes\":\"\",\"showcputime\":false,\"secret\":[]},{\"id\":\"6427055917_0.9575873512745192\",\"conflict\":\"false\",\"code\":\"from Notebook.DSNotebook.NotebookExecutor import NotebookExecutor\\nnb = NotebookExecutor()\\nnb.mssql_writer('shyam', 'Shy@8746dd8i23', 'bdbcirclek.c9lo3db08qkg.ap-south-1.rds.amazonaws.com', '1433', 'dslabtest', 'Limrick_data', df_Limrick)\",\"count\":11,\"mode\":\"preview\",\"type\":\"code\",\"hover\":true,\"interrupt\":false,\"warning\":false,\"outputArray\":[],\"lineNumber\":false,\"laodmodel\":false,\"pre_cell_id\":0,\"is_pre_cell\":false,\"succORerr\":true,\"expand\":false,\"outputexpand\":false,\"readonly\":false,\"markDowns\":false,\"loader\":false,\"image\":\"\",\"error\":\"\",\"result\":\"\",\"algorithms\":\"\",\"semicolon\":\"\",\"cputimes\":\"\",\"showcputime\":false,\"secret\":[]},{\"id\":\"6427055917_0.8354684183551644\",\"conflict\":\"false\",\"code\":\"from Notebook.DSNotebook.NotebookExecutor import NotebookExecutor\\nnb = NotebookExecutor()\\nnb.clickhouse_writer('username', 'password', 'host', 'port', 'database', 'tablename', df)\",\"count\":12,\"mode\":\"preview\",\"type\":\"code\",\"hover\":true,\"interrupt\":false,\"warning\":false,\"outputArray\":[],\"lineNumber\":false,\"laodmodel\":false,\"pre_cell_id\":0,\"is_pre_cell\":false,\"succORerr\":true,\"expand\":false,\"outputexpand\":false,\"readonly\":false,\"markDowns\":false,\"loader\":false,\"image\":\"\",\"error\":\"\",\"result\":\"\",\"algorithms\":\"\",\"semicolon\":\"\",\"cputimes\":\"\",\"showcputime\":false,\"secret\":[]}],\"kernalID\":\"f7803432-5588-47e1-9a2c-fbfe2033ecc1\",\"Algorithms\":[],\"isScheduled\":0,\"last_modified_date\":\"\"}","isImported":0,"customComponentscript":"{\"DSLAB_content\":\"[{\\\"id\\\":\\\"0_0.1783835660386166\\\",\\\"code\\\":\\\"def e_s():   \\\\n    from Notebook.DSNotebook.NotebookExecutor import NotebookExecutor \\\\n    nb = NotebookExecutor()\\\\n    df_HiringData = nb.get_data('11111718769832496', '@SYS.USERID', 'True', {}, [])\\\\n    return df_HiringData\\\",\\\"count\\\":0,\\\"error\\\":\\\"\\\",\\\"type\\\":\\\"code\\\",\\\"ischecked\\\":true}]\",\"pipeline_content\":\"\\\"def e_s():   \\\\n    from Notebook.DSNotebook.NotebookExecutor import NotebookExecutor \\\\n    nb = NotebookExecutor()\\\\n    df_HiringData = nb.get_data('11111718769832496', '@SYS.USERID', 'True', {}, [])\\\\n    return df_HiringData\\\"\",\"externalLibraries\":\"[{\\\"name\\\":\\\"boto3\\\",\\\"ischecked\\\":true},{\\\"name\\\":\\\"boto3\\\",\\\"ischecked\\\":true}]\"}","description":"","lastcommittedDate":1721367843064,"isScheduled":1,"committedBy":524290,"type":2,"uuid":"11111721367843124","loggedUserId":null,"spaceKey":"1111","migrationId":null,"path":"","lastUpdatedDate":1722512595780,"createdDate":1721367843064,"createdBy":524290,"notebookName":"Register as a Job","id":6427055917,"projectId":133093444,"isShared":null,"status":1}}