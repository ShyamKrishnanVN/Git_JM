{"cells": [{"cell_type": "code", "metadata": {"id": "70320191_0.8503873808360074"}, "execution_count": null, "source": ["from Notebook.DSNotebook.NotebookExecutor import NotebookExecutor\nnb = NotebookExecutor()\ndf_Shyam_ZomatoOne = nb.get_data('11111698993523301', '@SYS.USERID', 'False', {}, [], None, sparkSession)\ndf_Shyam_ZomatoOne.show(5)\n# The first function parameter refers to the service ID of the dataset.\n# @SYS.USERID refers to the user ID of the current user.\n# If the Sandbox key is 'false', it is referred to as a dataset, and if it's 'true', then the file is a sandbox file.\n# {} refers to the filters applied to the dataset.\n# [] refers to the data preparations applied to the dataset.\n# After [], users can specify the number of rows to limit the headcount of the dataset with a comma separator.\n# There will be a Spark session enabled in spark environment which will help user to get data."], "outputs": []}, {"cell_type": "code", "metadata": {"id": "73433203_0.9324863708772517"}, "execution_count": null, "source": ["from Notebook.DSNotebook.NotebookExecutor import NotebookExecutor\nnb = NotebookExecutor()\ndf_Abalone_data = nb.get_data('11111707390804200', '@SYS.USERID', 'True', {}, [], None, sparkSession)\ndf_Abalone_data.show(5)\n# The first function parameter refers to the service ID of the dataset.\n# @SYS.USERID refers to the user ID of the current user.\n# If the Sandbox key is 'false', it is referred to as a dataset, and if it's 'true', then the file is a sandbox file.\n# {} refers to the filters applied to the dataset.\n# [] refers to the data preparations applied to the dataset.\n# After [], users can specify the number of rows to limit the headcount of the dataset with a comma separator.\n# There will be a Spark session enabled in spark environment which will help user to get data."], "outputs": []}], "metadata": {}, "nbformat": 4, "nbformat_minor": 2}