{"featureSets":null,"autoML":null,"superFeatureSet":null,"errorMessage":null,"featureSet":null,"errorCode":null,"notebookModels":null,"message":"Successfully retrived!","notebookModelAsApi":null,"notebookScriptAsApi":null,"notebookModel":null,"notebookModelAsApis":null,"success":true,"notebooks":null,"customNotebookScript":null,"superFeatureSets":null,"messageCode":null,"stackTrace":null,"notebookContent":"{\"sucess\":true,\"content\":{\"cells\":[{\"cell_type\":\"markdown\",\"metadata\":{\"id\":\"0_0.9638239479529449\"},\"execution_count\":null,\"source\":[\"# Model fitting & training\"],\"outputs\":[]},{\"cell_type\":\"code\",\"metadata\":{\"id\":\"0_0.2103439605417201\"},\"execution_count\":null,\"source\":[\"#sklearn train model new_V888 \\nimport pandas as pd\\nfrom sklearn import model_selection\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.naive_bayes import GaussianNB\\nfrom sklearn.naive_bayes import MultinomialNB\\nfrom sklearn.linear_model import LinearRegression\\nimport pickle as pkle\\nurl = \\\"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\\\"\\nnames = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\\ndataframe = pd.read_csv(url, names=names)\\narray = dataframe.values\\nX = array[:,0:8]\\nY = array[:,8]\\ntest_size = 0.33\\nseed = 136\\nX_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, test_size=test_size, random_state=seed)\\nmodel = MultinomialNB()\\nmodel.fit(X_train, Y_train);\"],\"outputs\":[]},{\"cell_type\":\"markdown\",\"metadata\":{\"id\":\"0_0.06308231654560781\"},\"execution_count\":null,\"source\":[\"# Model Save\"],\"outputs\":[]},{\"cell_type\":\"code\",\"metadata\":{\"id\":\"0_0.8895035713387702\"},\"execution_count\":null,\"source\":[\"from Notebook.DSNotebook.NotebookExecutor import NotebookExecutor\\nnb = NotebookExecutor()\\nsaved_model = nb.save_model(model = model, modelName = 'Model_Class_Explainer_v2', modelType = 'ml', X = X_train, y = Y_train, estimator_type='classification')\\n#X and y are training datasets to get explainer dashboard.\\n#estimator_type is to specify algorithm type i.e., classification and regression.\\n#Only 'ml��� models with tabular data as input will support in Explainer Dashboard.\\n#Choose modelType = 'ml' for machine learning models, modelType = 'cv' for computer vision models and modelType = 'dp' for data transformation pickle files. \\n#Provide ���column_headers��� as a parameter if they have to be saved in the model.\\n#If using custom layer in keras, use native save functionality from keras.\"],\"outputs\":[]},{\"cell_type\":\"markdown\",\"metadata\":{\"id\":\"0_0.46732992129226725\"},\"execution_count\":null,\"source\":[\"# Model Load\"],\"outputs\":[]},{\"cell_type\":\"code\",\"metadata\":{\"id\":\"0_0.2916452729794454\"},\"execution_count\":null,\"source\":[\"from Notebook.DSNotebook.NotebookExecutor import NotebookExecutor\\nnb = NotebookExecutor()\\nloaded_model = nb.load_saved_model('11561706704411977')\"],\"outputs\":[]},{\"cell_type\":\"code\",\"metadata\":{\"id\":\"0_0.6409346578292987\"},\"execution_count\":null,\"source\":[\"X_test_copy = X_test.copy()\"],\"outputs\":[]},{\"cell_type\":\"markdown\",\"metadata\":{\"id\":\"0_0.6290525569145968\"},\"execution_count\":null,\"source\":[\"# Model Predict\"],\"outputs\":[]},{\"cell_type\":\"code\",\"metadata\":{\"id\":\"0_0.6779288838467916\"},\"execution_count\":null,\"source\":[\"nb.predict(model = loaded_model, dataframe = X_test_copy, modeltype='ml') \\n #Choose modeltype 'ml' for machine learning models and 'cv' for computer vision model \\n #ex: For machine learning model nb.predict(model = model, modeltype = 'ml', dataframe = df) \\n #ex: For computer vision keras model nb.predict(model = model, modeltype = 'cv', imgs = imgs, imgsize = (28, 28), dim = 1, class_names = class_names) \\n #and for pytorch model(model = model, modeltype = 'cv', imgs = imgs, class_names = class_names) \\n #Note: incase any error in prediction user squeezed image data in keras\"],\"outputs\":[]},{\"cell_type\":\"code\",\"metadata\":{\"id\":\"0_0.2620025051723418\"},\"execution_count\":null,\"source\":[\"X_test_copy = X_test.copy()\"],\"outputs\":[]},{\"cell_type\":\"code\",\"metadata\":{\"id\":\"0_0.6350241061566069\"},\"execution_count\":null,\"source\":[\"Y_pred = nb.predict(model = loaded_model, dataframe = X_test_copy, modeltype='ml') \"],\"outputs\":[]},{\"cell_type\":\"code\",\"metadata\":{\"id\":\"0_0.830874110204963\"},\"execution_count\":null,\"source\":[\"Y_pred.head()\"],\"outputs\":[]},{\"cell_type\":\"code\",\"metadata\":{\"id\":\"0_0.8478052239754741\"},\"execution_count\":null,\"source\":[\"from sklearn.metrics import accuracy_score\\naccuracy_score(Y_test, Y_pred.predictions)\"],\"outputs\":[]},{\"cell_type\":\"markdown\",\"metadata\":{\"id\":\"0_0.25656417574622914\"},\"execution_count\":null,\"source\":[\"# Sandbox file read\"],\"outputs\":[]},{\"cell_type\":\"code\",\"metadata\":{\"id\":\"0_0.05125267325157279\"},\"execution_count\":null,\"source\":[\"from Notebook.DSNotebook.NotebookExecutor import NotebookExecutor\\nnb = NotebookExecutor()\\ndf_Test_Data = nb.get_data('11561706704926924', '@SYS.USERID', 'True', {}, [])\\ndf_Test_Data.head()\"],\"outputs\":[]},{\"cell_type\":\"markdown\",\"metadata\":{\"id\":\"0_0.07161049493495364\"},\"execution_count\":null,\"source\":[\"# Artifacts file save\"],\"outputs\":[]},{\"cell_type\":\"code\",\"metadata\":{\"id\":\"0_0.034540902641922555\"},\"execution_count\":null,\"source\":[\"from Notebook.DSNotebook.NotebookExecutor import NotebookExecutor\\nnb = NotebookExecutor()\\n#File extension should be with .csv/.json/.txt\\nnb.save_artifact(dataframe = df_Test_Data, name = 'df_Test_Data.txt')\"],\"outputs\":[]},{\"cell_type\":\"markdown\",\"metadata\":{\"id\":\"0_0.647819846557842\"},\"execution_count\":null,\"source\":[\"# Artifacts saved file read\"],\"outputs\":[]},{\"cell_type\":\"code\",\"metadata\":{\"id\":\"0_0.27519725796295913\"},\"execution_count\":null,\"source\":[\"@SYS.ARTIFACT_PATH+'df_Test_Data.txt'\"],\"outputs\":[]},{\"cell_type\":\"code\",\"metadata\":{\"id\":\"0_0.3589486741705634\"},\"execution_count\":null,\"source\":[\"# print(open(@SYS.ARTIFACT_PATH+'df_Test_Data.txt').read())\\nnum_bytes_to_read = 1000\\nwith open(@SYS.ARTIFACT_PATH+'df_Test_Data.txt', 'r') as file:\\n    limited_data = file.read(num_bytes_to_read)\\nprint(limited_data)\"],\"outputs\":[]},{\"cell_type\":\"markdown\",\"metadata\":{\"id\":\"0_0.6698652165561829\"},\"execution_count\":null,\"source\":[\"# Reading uploaded file in forder structure\"],\"outputs\":[]},{\"cell_type\":\"code\",\"metadata\":{\"id\":\"0_0.6858879770414088\"},\"execution_count\":null,\"source\":[\"@SYS.DATASANDBOX_PATH + '135823364/Data/Folder_V1/Limerick_input_V1.xlsx'\"],\"outputs\":[]},{\"cell_type\":\"code\",\"metadata\":{\"id\":\"0_0.14392890045308904\"},\"execution_count\":null,\"source\":[\"pd.read_excel(@SYS.DATASANDBOX_PATH + '135823364/Data/Folder_V1/Limerick_input_V1.xlsx')\"],\"outputs\":[]},{\"cell_type\":\"markdown\",\"metadata\":{\"id\":\"0_0.7626980878680438\"},\"execution_count\":null,\"source\":[\"# Utility file read\"],\"outputs\":[]},{\"cell_type\":\"code\",\"metadata\":{\"id\":\"0_0.027072296228531245\"},\"execution_count\":null,\"source\":[\"from Utiity_script_V33 import Person\\nFuture = Person(\\\"Shyam\\\", \\\"29\\\")\\nprint(Future.name)\\nprint(Future.age)\"],\"outputs\":[]},{\"cell_type\":\"code\",\"metadata\":{\"id\":\"0_0.25927394998460707\"},\"execution_count\":null,\"source\":[\"from Utiity_script_V33 import Person\\nimport inspect\\nsource_code = inspect.getsource(Person)\\nprint(source_code)\"],\"outputs\":[]},{\"cell_type\":\"markdown\",\"metadata\":{\"id\":\"0_0.9142356732528032\"},\"execution_count\":null,\"source\":[\"# Data Transformation save\"],\"outputs\":[]},{\"cell_type\":\"code\",\"metadata\":{\"id\":\"0_0.981445708815591\"},\"execution_count\":null,\"source\":[\"from sklearn.datasets import make_blobs\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.preprocessing import MinMaxScaler\\nfrom sklearn.linear_model import LogisticRegression\\nfrom pickle import dump\\n# prepare dataset\\nX, y = make_blobs(n_samples=100, centers=2, n_features=2, random_state=1)\\n# split data into train and test sets\\nX_train, _, y_train, _ = train_test_split(X, y, test_size=0.33, random_state=1)\\n# define scaler\\nscaler = MinMaxScaler()\\n# fit scaler on the training dataset\\nscaler.fit(X_train);\\n# transform the training dataset\\nX_train_scaled = scaler.transform(X_train)\\nfrom Notebook.DSNotebook.NotebookExecutor import NotebookExecutor\\nnb = NotebookExecutor()\\nsaved_model = nb.save_model(model = scaler, modelName = 'ScalerTransform', modelType = 'dp', X = None, y = None, estimator_type='')\\n#X and y are training datasets to get explainer dashboard.\\n#estimator_type is to specify algorithm type i.e., classification and regression.\\n#Only 'ml��� models with tabular data as input will support in Explainer Dashboard.\\n#Choose modelType = 'ml' for machine learning models, modelType = 'cv' for computer vision models and modelType = 'dp' for data transformation pickle files. \\n#Provide ���column_headers��� as a parameter if they have to be saved in the model.\\n#If using custom layer in keras, use native save functionality from keras.\"],\"outputs\":[]},{\"cell_type\":\"markdown\",\"metadata\":{\"id\":\"0_0.3201147619263187\"},\"execution_count\":null,\"source\":[\"# Transformation load\"],\"outputs\":[]},{\"cell_type\":\"code\",\"metadata\":{\"id\":\"0_0.39181063277450034\"},\"execution_count\":null,\"source\":[\"from Notebook.DSNotebook.NotebookExecutor import NotebookExecutor\\nnb = NotebookExecutor()\\nloaded_model = nb.load_model('11561706705620074')\"],\"outputs\":[]},{\"cell_type\":\"markdown\",\"metadata\":{\"id\":\"0_0.20280194577293154\"},\"execution_count\":null,\"source\":[\"# Transforming traing data\"],\"outputs\":[]},{\"cell_type\":\"code\",\"metadata\":{\"id\":\"0_0.3821692720277108\"},\"execution_count\":null,\"source\":[\"loaded_model.transform(X_train)\"],\"outputs\":[]},{\"cell_type\":\"code\",\"metadata\":{\"id\":\"0_0.4067671569623674\"},\"execution_count\":null,\"source\":[\"import PyPDF2\\n\\ndef read_pdf(file_path):\\n    with open(file_path, 'rb') as file:\\n        reader = PyPDF2.PdfFileReader(file)\\n        number_of_pages = reader.getNumPages()\\n        print(f'The PDF has {number_of_pages} pages.')\\n        for page_number in range(number_of_pages):\\n            page = reader.getPage(page_number)\\n            print(page.extract_text())\\n\\nfile_path = @SYS.DATASANDBOX_PATH + '49741845/Data/DS Lab Features.pdf'\\nread_pdf(file_path)\"],\"outputs\":[]}],\"metadata\":{},\"nbformat\":4,\"nbformat_minor\":2}}","bizvizNotebook":null,"autoMLs":null,"scripts":null,"bizvizNotebooks":null,"notebook":{"mongoQL":null,"updatedBy":3423206633,"data":"{\"datasets\":[],\"uncheckeddatasets\":[],\"code\":[{\"id\":\"0_0.9638239479529449\",\"code\":\"# Model fitting & training\",\"count\":1,\"mode\":\"preview\",\"type\":\"markdown\",\"pre_cell_id\":0,\"is_pre_cell\":false,\"succORerr\":true,\"hover\":true,\"interrupt\":false,\"warning\":false,\"lineNumber\":false,\"laodmodel\":false,\"expand\":false,\"outputexpand\":false,\"readonly\":false,\"markDowns\":false,\"algorithms\":\"\",\"semicolon\":\"\",\"cputimes\":\"\",\"showcputime\":false,\"secret\":[],\"loader\":false,\"image\":\"\",\"error\":\"\",\"result\":\"\"},{\"id\":\"0_0.2103439605417201\",\"code\":\"#sklearn train model new_V888 \\nimport pandas as pd\\nfrom sklearn import model_selection\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.naive_bayes import GaussianNB\\nfrom sklearn.naive_bayes import MultinomialNB\\nfrom sklearn.linear_model import LinearRegression\\nimport pickle as pkle\\nurl = \\\"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\\\"\\nnames = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\\ndataframe = pd.read_csv(url, names=names)\\narray = dataframe.values\\nX = array[:,0:8]\\nY = array[:,8]\\ntest_size = 0.33\\nseed = 136\\nX_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, test_size=test_size, random_state=seed)\\nmodel = MultinomialNB()\\nmodel.fit(X_train, Y_train);\",\"count\":2,\"mode\":\"preview\",\"type\":\"code\",\"pre_cell_id\":0,\"is_pre_cell\":false,\"succORerr\":true,\"hover\":true,\"interrupt\":false,\"warning\":false,\"lineNumber\":false,\"laodmodel\":false,\"expand\":false,\"outputexpand\":false,\"readonly\":false,\"markDowns\":false,\"algorithms\":\"\",\"semicolon\":\"\",\"cputimes\":\"\",\"showcputime\":false,\"secret\":[],\"loader\":false,\"image\":\"\",\"error\":\"\",\"result\":\"\"},{\"id\":\"0_0.06308231654560781\",\"code\":\"# Model Save\",\"count\":3,\"mode\":\"preview\",\"type\":\"markdown\",\"pre_cell_id\":0,\"is_pre_cell\":false,\"succORerr\":true,\"hover\":true,\"interrupt\":false,\"warning\":false,\"lineNumber\":false,\"laodmodel\":false,\"expand\":false,\"outputexpand\":false,\"readonly\":false,\"markDowns\":false,\"algorithms\":\"\",\"semicolon\":\"\",\"cputimes\":\"\",\"showcputime\":false,\"secret\":[],\"loader\":false,\"image\":\"\",\"error\":\"\",\"result\":\"\"},{\"id\":\"0_0.8895035713387702\",\"code\":\"from Notebook.DSNotebook.NotebookExecutor import NotebookExecutor\\nnb = NotebookExecutor()\\nsaved_model = nb.save_model(model = model, modelName = 'Model_Class_Explainer_v2', modelType = 'ml', X = X_train, y = Y_train, estimator_type='classification')\\n#X and y are training datasets to get explainer dashboard.\\n#estimator_type is to specify algorithm type i.e., classification and regression.\\n#Only 'ml��� models with tabular data as input will support in Explainer Dashboard.\\n#Choose modelType = 'ml' for machine learning models, modelType = 'cv' for computer vision models and modelType = 'dp' for data transformation pickle files. \\n#Provide ���column_headers��� as a parameter if they have to be saved in the model.\\n#If using custom layer in keras, use native save functionality from keras.\",\"count\":4,\"mode\":\"preview\",\"type\":\"code\",\"pre_cell_id\":0,\"is_pre_cell\":false,\"succORerr\":false,\"hover\":true,\"interrupt\":false,\"warning\":false,\"lineNumber\":false,\"laodmodel\":false,\"expand\":false,\"outputexpand\":false,\"readonly\":false,\"markDowns\":false,\"algorithms\":\"\",\"semicolon\":\"\",\"cputimes\":\"\",\"showcputime\":false,\"secret\":[],\"loader\":false,\"image\":\"\",\"result\":\"\",\"outputArray\":\"\",\"error\":\"\"},{\"id\":\"0_0.46732992129226725\",\"code\":\"# Model Load\",\"count\":5,\"mode\":\"preview\",\"type\":\"markdown\",\"pre_cell_id\":0,\"is_pre_cell\":false,\"succORerr\":true,\"hover\":true,\"interrupt\":false,\"warning\":false,\"lineNumber\":false,\"laodmodel\":false,\"expand\":false,\"outputexpand\":false,\"readonly\":false,\"markDowns\":false,\"algorithms\":\"\",\"semicolon\":\"\",\"cputimes\":\"\",\"showcputime\":false,\"secret\":[],\"loader\":false,\"image\":\"\",\"error\":\"\",\"result\":\"\"},{\"id\":\"0_0.2916452729794454\",\"code\":\"from Notebook.DSNotebook.NotebookExecutor import NotebookExecutor\\nnb = NotebookExecutor()\\nloaded_model = nb.load_saved_model('11561706704411977')\",\"count\":6,\"mode\":\"preview\",\"type\":\"code\",\"pre_cell_id\":0,\"is_pre_cell\":false,\"succORerr\":false,\"hover\":true,\"interrupt\":false,\"warning\":false,\"lineNumber\":false,\"laodmodel\":false,\"expand\":false,\"outputexpand\":false,\"readonly\":false,\"markDowns\":false,\"algorithms\":\"\",\"semicolon\":\"\",\"cputimes\":\"\",\"showcputime\":false,\"secret\":[],\"loader\":false,\"image\":\"\",\"result\":\"\",\"outputArray\":\"\",\"error\":\"\"},{\"id\":\"0_0.6409346578292987\",\"code\":\"X_test_copy = X_test.copy()\",\"count\":7,\"mode\":\"preview\",\"type\":\"code\",\"pre_cell_id\":0,\"is_pre_cell\":false,\"succORerr\":true,\"hover\":true,\"interrupt\":false,\"warning\":false,\"lineNumber\":false,\"laodmodel\":false,\"expand\":false,\"outputexpand\":false,\"readonly\":false,\"markDowns\":false,\"algorithms\":\"\",\"semicolon\":\"\",\"cputimes\":\"\",\"showcputime\":false,\"secret\":[],\"loader\":false,\"image\":\"\",\"error\":\"\",\"result\":\"\"},{\"id\":\"0_0.6290525569145968\",\"code\":\"# Model Predict\",\"count\":8,\"mode\":\"preview\",\"type\":\"markdown\",\"pre_cell_id\":0,\"is_pre_cell\":false,\"succORerr\":true,\"hover\":true,\"interrupt\":false,\"warning\":false,\"lineNumber\":false,\"laodmodel\":false,\"expand\":false,\"outputexpand\":false,\"readonly\":false,\"markDowns\":false,\"algorithms\":\"\",\"semicolon\":\"\",\"cputimes\":\"\",\"showcputime\":false,\"secret\":[],\"loader\":false,\"image\":\"\",\"error\":\"\",\"result\":\"\"},{\"id\":\"0_0.6779288838467916\",\"code\":\"nb.predict(model = loaded_model, dataframe = X_test_copy, modeltype='ml') \\n #Choose modeltype 'ml' for machine learning models and 'cv' for computer vision model \\n #ex: For machine learning model nb.predict(model = model, modeltype = 'ml', dataframe = df) \\n #ex: For computer vision keras model nb.predict(model = model, modeltype = 'cv', imgs = imgs, imgsize = (28, 28), dim = 1, class_names = class_names) \\n #and for pytorch model(model = model, modeltype = 'cv', imgs = imgs, class_names = class_names) \\n #Note: incase any error in prediction user squeezed image data in keras\",\"count\":9,\"mode\":\"preview\",\"type\":\"code\",\"pre_cell_id\":0,\"is_pre_cell\":false,\"succORerr\":false,\"hover\":true,\"interrupt\":false,\"warning\":false,\"lineNumber\":false,\"laodmodel\":false,\"expand\":false,\"outputexpand\":false,\"readonly\":false,\"markDowns\":false,\"algorithms\":\"\",\"semicolon\":\"\",\"cputimes\":\"\",\"showcputime\":false,\"secret\":[],\"loader\":false,\"image\":\"\",\"result\":\"\",\"outputArray\":\"\",\"error\":\"\"},{\"id\":\"0_0.2620025051723418\",\"code\":\"X_test_copy = X_test.copy()\",\"count\":10,\"mode\":\"preview\",\"type\":\"code\",\"pre_cell_id\":0,\"is_pre_cell\":false,\"succORerr\":true,\"hover\":true,\"interrupt\":false,\"warning\":false,\"lineNumber\":false,\"laodmodel\":false,\"expand\":false,\"outputexpand\":false,\"readonly\":false,\"markDowns\":false,\"algorithms\":\"\",\"semicolon\":\"\",\"cputimes\":\"\",\"showcputime\":false,\"secret\":[],\"loader\":false,\"image\":\"\",\"error\":\"\",\"result\":\"\"},{\"id\":\"0_0.6350241061566069\",\"code\":\"Y_pred = nb.predict(model = loaded_model, dataframe = X_test_copy, modeltype='ml') \",\"count\":11,\"mode\":\"preview\",\"type\":\"code\",\"pre_cell_id\":0,\"is_pre_cell\":false,\"succORerr\":false,\"hover\":true,\"interrupt\":false,\"warning\":false,\"lineNumber\":false,\"laodmodel\":false,\"expand\":false,\"outputexpand\":false,\"readonly\":false,\"markDowns\":false,\"algorithms\":\"\",\"semicolon\":\"\",\"cputimes\":\"\",\"showcputime\":false,\"secret\":[],\"loader\":false,\"image\":\"\",\"result\":\"\",\"outputArray\":\"\",\"error\":\"\"},{\"id\":\"0_0.830874110204963\",\"code\":\"Y_pred.head()\",\"count\":12,\"mode\":\"preview\",\"type\":\"code\",\"pre_cell_id\":0,\"is_pre_cell\":false,\"succORerr\":false,\"hover\":true,\"interrupt\":false,\"warning\":false,\"lineNumber\":false,\"laodmodel\":false,\"expand\":false,\"outputexpand\":false,\"readonly\":false,\"markDowns\":false,\"algorithms\":\"\",\"semicolon\":\"\",\"cputimes\":\"\",\"showcputime\":false,\"secret\":[],\"loader\":false,\"image\":\"\",\"result\":\"\",\"outputArray\":\"\",\"error\":\"\"},{\"id\":\"0_0.8478052239754741\",\"code\":\"from sklearn.metrics import accuracy_score\\naccuracy_score(Y_test, Y_pred.predictions)\",\"count\":13,\"mode\":\"preview\",\"type\":\"code\",\"pre_cell_id\":0,\"is_pre_cell\":false,\"succORerr\":false,\"hover\":true,\"interrupt\":false,\"warning\":false,\"lineNumber\":false,\"laodmodel\":false,\"expand\":false,\"outputexpand\":false,\"readonly\":false,\"markDowns\":false,\"algorithms\":\"\",\"semicolon\":\"\",\"cputimes\":\"\",\"showcputime\":false,\"secret\":[],\"loader\":false,\"image\":\"\",\"result\":\"\",\"outputArray\":\"\",\"error\":\"\"},{\"id\":\"0_0.25656417574622914\",\"code\":\"# Sandbox file read\",\"count\":14,\"mode\":\"preview\",\"type\":\"markdown\",\"pre_cell_id\":0,\"is_pre_cell\":false,\"succORerr\":true,\"hover\":true,\"interrupt\":false,\"warning\":false,\"lineNumber\":false,\"laodmodel\":false,\"expand\":false,\"outputexpand\":false,\"readonly\":false,\"markDowns\":false,\"algorithms\":\"\",\"semicolon\":\"\",\"cputimes\":\"\",\"showcputime\":false,\"secret\":[],\"loader\":false,\"image\":\"\",\"error\":\"\",\"result\":\"\"},{\"id\":\"0_0.05125267325157279\",\"code\":\"from Notebook.DSNotebook.NotebookExecutor import NotebookExecutor\\nnb = NotebookExecutor()\\ndf_Test_Data = nb.get_data('11561706704926924', '@SYS.USERID', 'True', {}, [])\\ndf_Test_Data.head()\",\"count\":15,\"mode\":\"preview\",\"type\":\"code\",\"pre_cell_id\":0,\"is_pre_cell\":false,\"succORerr\":true,\"hover\":true,\"interrupt\":false,\"warning\":false,\"lineNumber\":false,\"laodmodel\":false,\"expand\":false,\"outputexpand\":false,\"readonly\":false,\"markDowns\":false,\"algorithms\":\"\",\"semicolon\":\"\",\"cputimes\":\"\",\"showcputime\":false,\"secret\":[],\"loader\":false,\"image\":\"\",\"error\":\"\",\"outputArray\":[\"ERROR:root:Error while readig data 11561706704926924 'queryService'\\n\",{\"traceback\":[\"---------------------------------------------------------------------------\",\"Exception                                 Traceback (most recent call last)\",\"Cell In[10], line 3\\n      1 from Notebook.DSNotebook.NotebookExecutor import NotebookExecutor\\n      2 nb = NotebookExecutor()\\n----> 3 df_Test_Data = nb.get_data('11561706704926924', '48201728', 'True', {}, [])\\n      4 df_Test_Data.head()\\n\",\"File /app/Notebook/DSNotebook/NotebookExecutor.py:1460, in NotebookExecutor.get_data(self, serviceID, UserID, Sandbox, filters, prep_ids, limit, spark, version)\\n   1458 except Exception as e:\\n   1459     logging.error(f\\\"Error while readig data {serviceID} {str(e)}\\\")\\n-> 1460     raise Exception(e) from None\\n   1461 finally:\\n   1462     os.chdir(f'{os.environ[\\\"DATASANDBOX_PATH\\\"]}/{os.environ[\\\"SPACE_KEY\\\"]}/{os.environ[\\\"PROJECT_ID\\\"]}')\\n\",\"Exception: 'queryService'\"],\"ename\":\"Exception\",\"evalue\":\"'queryService'\",\"output_type\":\"error\",\"final_output\":\"---------------------------------------------------------------------------\\nException                                 Traceback (most recent call last)\\nCell In[10], line 3\\n      1 from Notebook.DSNotebook.NotebookExecutor import NotebookExecutor\\n      2 nb = NotebookExecutor()\\n----> 3 df_Test_Data = nb.get_data('11561706704926924', '48201728', 'True', {}, [])\\n      4 df_Test_Data.head()\\n\\nFile /app/Notebook/DSNotebook/NotebookExecutor.py:1460, in NotebookExecutor.get_data(self, serviceID, UserID, Sandbox, filters, prep_ids, limit, spark, version)\\n   1458 except Exception as e:\\n   1459     logging.error(f\\\"Error while readig data {serviceID} {str(e)}\\\")\\n-> 1460     raise Exception(e) from None\\n   1461 finally:\\n   1462     os.chdir(f'{os.environ[\\\"DATASANDBOX_PATH\\\"]}/{os.environ[\\\"SPACE_KEY\\\"]}/{os.environ[\\\"PROJECT_ID\\\"]}')\\n\\nException: 'queryService'\"}],\"result\":\"\"},{\"id\":\"0_0.07161049493495364\",\"code\":\"# Artifacts file save\",\"count\":16,\"mode\":\"preview\",\"type\":\"markdown\",\"pre_cell_id\":0,\"is_pre_cell\":false,\"succORerr\":true,\"hover\":true,\"interrupt\":false,\"warning\":false,\"lineNumber\":false,\"laodmodel\":false,\"expand\":false,\"outputexpand\":false,\"readonly\":false,\"markDowns\":false,\"algorithms\":\"\",\"semicolon\":\"\",\"cputimes\":\"\",\"showcputime\":false,\"secret\":[],\"loader\":false,\"image\":\"\",\"error\":\"\",\"result\":\"\"},{\"id\":\"0_0.034540902641922555\",\"code\":\"from Notebook.DSNotebook.NotebookExecutor import NotebookExecutor\\nnb = NotebookExecutor()\\n#File extension should be with .csv/.json/.txt\\nnb.save_artifact(dataframe = df_Test_Data, name = 'df_Test_Data.txt')\",\"count\":17,\"mode\":\"preview\",\"type\":\"code\",\"pre_cell_id\":0,\"is_pre_cell\":false,\"succORerr\":false,\"hover\":true,\"interrupt\":false,\"warning\":false,\"lineNumber\":false,\"laodmodel\":false,\"expand\":false,\"outputexpand\":false,\"readonly\":false,\"markDowns\":false,\"algorithms\":\"\",\"semicolon\":\"\",\"cputimes\":\"\",\"showcputime\":false,\"secret\":[],\"loader\":false,\"image\":\"\",\"result\":\"\",\"outputArray\":\"\",\"error\":\"\"},{\"id\":\"0_0.647819846557842\",\"code\":\"# Artifacts saved file read\",\"count\":18,\"mode\":\"preview\",\"type\":\"markdown\",\"pre_cell_id\":0,\"is_pre_cell\":false,\"succORerr\":true,\"hover\":true,\"interrupt\":false,\"warning\":false,\"lineNumber\":false,\"laodmodel\":false,\"expand\":false,\"outputexpand\":false,\"readonly\":false,\"markDowns\":false,\"algorithms\":\"\",\"semicolon\":\"\",\"cputimes\":\"\",\"showcputime\":false,\"secret\":[],\"loader\":false,\"image\":\"\",\"error\":\"\",\"result\":\"\"},{\"id\":\"0_0.27519725796295913\",\"code\":\"@SYS.ARTIFACT_PATH+'df_Test_Data.txt'\",\"count\":19,\"mode\":\"preview\",\"type\":\"code\",\"pre_cell_id\":0,\"is_pre_cell\":false,\"succORerr\":true,\"hover\":true,\"interrupt\":false,\"warning\":false,\"lineNumber\":false,\"laodmodel\":false,\"expand\":false,\"outputexpand\":false,\"readonly\":false,\"markDowns\":false,\"algorithms\":\"\",\"semicolon\":\"\",\"cputimes\":\"\",\"showcputime\":false,\"secret\":[],\"loader\":false,\"image\":\"\",\"error\":\"\",\"result\":\"\"},{\"id\":\"0_0.3589486741705634\",\"code\":\"# print(open(@SYS.ARTIFACT_PATH+'df_Test_Data.txt').read())\\nnum_bytes_to_read = 1000\\nwith open(@SYS.ARTIFACT_PATH+'df_Test_Data.txt', 'r') as file:\\n    limited_data = file.read(num_bytes_to_read)\\nprint(limited_data)\",\"count\":20,\"mode\":\"preview\",\"type\":\"code\",\"pre_cell_id\":0,\"is_pre_cell\":false,\"succORerr\":false,\"hover\":true,\"interrupt\":false,\"warning\":false,\"lineNumber\":false,\"laodmodel\":false,\"expand\":false,\"outputexpand\":false,\"readonly\":false,\"markDowns\":false,\"algorithms\":\"\",\"semicolon\":\"\",\"cputimes\":\"\",\"showcputime\":false,\"secret\":[],\"loader\":false,\"image\":\"\",\"result\":\"\",\"outputArray\":\"\",\"error\":\"\"},{\"id\":\"0_0.6698652165561829\",\"code\":\"# Reading uploaded file in forder structure\",\"count\":21,\"mode\":\"preview\",\"type\":\"markdown\",\"pre_cell_id\":0,\"is_pre_cell\":false,\"succORerr\":true,\"hover\":true,\"interrupt\":false,\"warning\":false,\"lineNumber\":false,\"laodmodel\":false,\"expand\":false,\"outputexpand\":false,\"readonly\":false,\"markDowns\":false,\"algorithms\":\"\",\"semicolon\":\"\",\"cputimes\":\"\",\"showcputime\":false,\"secret\":[],\"loader\":false,\"image\":\"\",\"error\":\"\",\"result\":\"\"},{\"id\":\"0_0.6858879770414088\",\"code\":\"@SYS.DATASANDBOX_PATH + '135823364/Data/Folder_V1/Limerick_input_V1.xlsx'\",\"count\":22,\"mode\":\"preview\",\"type\":\"code\",\"pre_cell_id\":0,\"is_pre_cell\":false,\"succORerr\":true,\"hover\":true,\"interrupt\":false,\"warning\":false,\"lineNumber\":false,\"laodmodel\":false,\"expand\":false,\"outputexpand\":false,\"readonly\":false,\"markDowns\":false,\"algorithms\":\"\",\"semicolon\":\"\",\"cputimes\":\"\",\"showcputime\":false,\"secret\":[],\"loader\":false,\"image\":\"\",\"error\":\"\",\"result\":\"\"},{\"id\":\"0_0.14392890045308904\",\"code\":\"pd.read_excel(@SYS.DATASANDBOX_PATH + '135823364/Data/Folder_V1/Limerick_input_V1.xlsx')\",\"count\":23,\"mode\":\"preview\",\"type\":\"code\",\"pre_cell_id\":0,\"is_pre_cell\":false,\"succORerr\":false,\"hover\":true,\"interrupt\":false,\"warning\":false,\"lineNumber\":false,\"laodmodel\":false,\"expand\":false,\"outputexpand\":false,\"readonly\":false,\"markDowns\":false,\"algorithms\":\"\",\"semicolon\":\"\",\"cputimes\":\"\",\"showcputime\":false,\"secret\":[],\"loader\":false,\"image\":\"\",\"result\":\"\",\"outputArray\":\"\",\"error\":\"\"},{\"id\":\"0_0.7626980878680438\",\"code\":\"# Utility file read\",\"count\":24,\"mode\":\"preview\",\"type\":\"markdown\",\"pre_cell_id\":0,\"is_pre_cell\":false,\"succORerr\":true,\"hover\":true,\"interrupt\":false,\"warning\":false,\"lineNumber\":false,\"laodmodel\":false,\"expand\":false,\"outputexpand\":false,\"readonly\":false,\"markDowns\":false,\"algorithms\":\"\",\"semicolon\":\"\",\"cputimes\":\"\",\"showcputime\":false,\"secret\":[],\"loader\":false,\"image\":\"\",\"error\":\"\",\"result\":\"\"},{\"id\":\"0_0.027072296228531245\",\"code\":\"from Utiity_script_V33 import Person\\nFuture = Person(\\\"Shyam\\\", \\\"29\\\")\\nprint(Future.name)\\nprint(Future.age)\",\"count\":25,\"mode\":\"preview\",\"type\":\"code\",\"pre_cell_id\":0,\"is_pre_cell\":false,\"succORerr\":true,\"hover\":true,\"interrupt\":false,\"warning\":false,\"lineNumber\":false,\"laodmodel\":false,\"expand\":false,\"outputexpand\":false,\"readonly\":false,\"markDowns\":false,\"algorithms\":\"\",\"semicolon\":\"\",\"cputimes\":\"\",\"showcputime\":false,\"secret\":[],\"loader\":false,\"image\":\"\",\"error\":\"\",\"result\":\"\"},{\"id\":\"0_0.25927394998460707\",\"code\":\"from Utiity_script_V33 import Person\\nimport inspect\\nsource_code = inspect.getsource(Person)\\nprint(source_code)\",\"count\":26,\"mode\":\"preview\",\"type\":\"code\",\"pre_cell_id\":0,\"is_pre_cell\":false,\"succORerr\":true,\"hover\":true,\"interrupt\":false,\"warning\":false,\"lineNumber\":false,\"laodmodel\":false,\"expand\":false,\"outputexpand\":false,\"readonly\":false,\"markDowns\":false,\"algorithms\":\"\",\"semicolon\":\"\",\"cputimes\":\"\",\"showcputime\":false,\"secret\":[],\"loader\":false,\"image\":\"\",\"error\":\"\",\"result\":\"\"},{\"id\":\"0_0.9142356732528032\",\"code\":\"# Data Transformation save\",\"count\":27,\"mode\":\"preview\",\"type\":\"markdown\",\"pre_cell_id\":0,\"is_pre_cell\":false,\"succORerr\":true,\"hover\":true,\"interrupt\":false,\"warning\":false,\"lineNumber\":false,\"laodmodel\":false,\"expand\":false,\"outputexpand\":false,\"readonly\":false,\"markDowns\":false,\"algorithms\":\"\",\"semicolon\":\"\",\"cputimes\":\"\",\"showcputime\":false,\"secret\":[],\"loader\":false,\"image\":\"\",\"error\":\"\",\"result\":\"\"},{\"id\":\"0_0.981445708815591\",\"code\":\"from sklearn.datasets import make_blobs\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.preprocessing import MinMaxScaler\\nfrom sklearn.linear_model import LogisticRegression\\nfrom pickle import dump\\n# prepare dataset\\nX, y = make_blobs(n_samples=100, centers=2, n_features=2, random_state=1)\\n# split data into train and test sets\\nX_train, _, y_train, _ = train_test_split(X, y, test_size=0.33, random_state=1)\\n# define scaler\\nscaler = MinMaxScaler()\\n# fit scaler on the training dataset\\nscaler.fit(X_train);\\n# transform the training dataset\\nX_train_scaled = scaler.transform(X_train)\\nfrom Notebook.DSNotebook.NotebookExecutor import NotebookExecutor\\nnb = NotebookExecutor()\\nsaved_model = nb.save_model(model = scaler, modelName = 'ScalerTransform', modelType = 'dp', X = None, y = None, estimator_type='')\\n#X and y are training datasets to get explainer dashboard.\\n#estimator_type is to specify algorithm type i.e., classification and regression.\\n#Only 'ml��� models with tabular data as input will support in Explainer Dashboard.\\n#Choose modelType = 'ml' for machine learning models, modelType = 'cv' for computer vision models and modelType = 'dp' for data transformation pickle files. \\n#Provide ���column_headers��� as a parameter if they have to be saved in the model.\\n#If using custom layer in keras, use native save functionality from keras.\",\"count\":28,\"mode\":\"preview\",\"type\":\"code\",\"pre_cell_id\":0,\"is_pre_cell\":false,\"succORerr\":true,\"hover\":true,\"interrupt\":false,\"warning\":false,\"lineNumber\":false,\"laodmodel\":false,\"expand\":false,\"outputexpand\":false,\"readonly\":false,\"markDowns\":false,\"algorithms\":\"\",\"semicolon\":\"\",\"cputimes\":\"\",\"showcputime\":false,\"secret\":[],\"loader\":false,\"image\":\"\",\"error\":\"\",\"result\":\"\"},{\"id\":\"0_0.3201147619263187\",\"code\":\"# Transformation load\",\"count\":29,\"mode\":\"preview\",\"type\":\"markdown\",\"pre_cell_id\":0,\"is_pre_cell\":false,\"succORerr\":true,\"hover\":true,\"interrupt\":false,\"warning\":false,\"lineNumber\":false,\"laodmodel\":false,\"expand\":false,\"outputexpand\":false,\"readonly\":false,\"markDowns\":false,\"algorithms\":\"\",\"semicolon\":\"\",\"cputimes\":\"\",\"showcputime\":false,\"secret\":[],\"loader\":false,\"image\":\"\",\"error\":\"\",\"result\":\"\"},{\"id\":\"0_0.39181063277450034\",\"code\":\"from Notebook.DSNotebook.NotebookExecutor import NotebookExecutor\\nnb = NotebookExecutor()\\nloaded_model = nb.load_model('11561706705620074')\",\"count\":30,\"mode\":\"preview\",\"type\":\"code\",\"pre_cell_id\":0,\"is_pre_cell\":false,\"succORerr\":false,\"hover\":true,\"interrupt\":false,\"warning\":false,\"lineNumber\":false,\"laodmodel\":false,\"expand\":false,\"outputexpand\":false,\"readonly\":false,\"markDowns\":false,\"algorithms\":\"\",\"semicolon\":\"\",\"cputimes\":\"\",\"showcputime\":false,\"secret\":[],\"loader\":false,\"image\":\"\",\"result\":\"\",\"outputArray\":\"\",\"error\":\"\"},{\"id\":\"0_0.20280194577293154\",\"code\":\"# Transforming traing data\",\"count\":31,\"mode\":\"preview\",\"type\":\"markdown\",\"pre_cell_id\":0,\"is_pre_cell\":false,\"succORerr\":true,\"hover\":true,\"interrupt\":false,\"warning\":false,\"lineNumber\":false,\"laodmodel\":false,\"expand\":false,\"outputexpand\":false,\"readonly\":false,\"markDowns\":false,\"algorithms\":\"\",\"semicolon\":\"\",\"cputimes\":\"\",\"showcputime\":false,\"secret\":[],\"loader\":false,\"image\":\"\",\"error\":\"\",\"result\":\"\"},{\"id\":\"0_0.3821692720277108\",\"code\":\"loaded_model.transform(X_train)\",\"count\":32,\"mode\":\"preview\",\"type\":\"code\",\"pre_cell_id\":0,\"is_pre_cell\":false,\"succORerr\":false,\"hover\":true,\"interrupt\":false,\"warning\":false,\"lineNumber\":false,\"laodmodel\":false,\"expand\":false,\"outputexpand\":false,\"readonly\":false,\"markDowns\":false,\"algorithms\":\"\",\"semicolon\":\"\",\"cputimes\":\"\",\"showcputime\":false,\"secret\":[],\"loader\":false,\"image\":\"\",\"result\":\"\",\"outputArray\":\"\",\"error\":\"\"},{\"id\":\"0_0.4067671569623674\",\"code\":\"import PyPDF2\\n\\ndef read_pdf(file_path):\\n    with open(file_path, 'rb') as file:\\n        reader = PyPDF2.PdfFileReader(file)\\n        number_of_pages = reader.getNumPages()\\n        print(f'The PDF has {number_of_pages} pages.')\\n        for page_number in range(number_of_pages):\\n            page = reader.getPage(page_number)\\n            print(page.extract_text())\\n\\nfile_path = @SYS.DATASANDBOX_PATH + '49741845/Data/DS Lab Features.pdf'\\nread_pdf(file_path)\",\"count\":33,\"mode\":\"preview\",\"type\":\"code\",\"pre_cell_id\":0,\"is_pre_cell\":false,\"succORerr\":true,\"hover\":true,\"interrupt\":false,\"warning\":false,\"lineNumber\":false,\"laodmodel\":false,\"expand\":false,\"outputexpand\":false,\"readonly\":false,\"markDowns\":false,\"algorithms\":\"\",\"semicolon\":\"\",\"cputimes\":\"\",\"showcputime\":false,\"secret\":[],\"loader\":false,\"image\":\"\",\"error\":\"\",\"result\":\"\"}],\"kernalID\":\"\",\"Algorithms\":[],\"isScheduled\":0,\"last_modified_date\":\"\"}","isImported":0,"customComponentscript":"","description":"","lastcommittedDate":1727937502421,"isScheduled":null,"committedBy":3423206633,"type":1,"uuid":"52311727937502506","loggedUserId":null,"spaceKey":"5231","migrationId":null,"path":"","lastUpdatedDate":1727937502506,"createdDate":1727937502421,"createdBy":3423206633,"notebookName":"SKL","id":34036191193,"projectId":33461208333,"isShared":null,"status":1}}