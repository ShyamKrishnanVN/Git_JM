{"cells": [{"cell_type": "markdown", "metadata": {"id": "136347704_0.6116797367087223"}, "execution_count": null, "source": ["# Model fitting & training"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "136347704_0.2191253297824194"}, "execution_count": 1, "source": ["#sklearn train model new_V888 \nimport pandas as pds\nfrom sklearn import model_selection\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.naive_bayes import MultinomialNB\nimport pickle as pkle\nurl = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\nnames = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\ndataframe = pd.read_csv(url, names=names)\narray = dataframe.values\nX = array[:,0:8]\nY = array[:,8]\ntest_size = 0.33\nseed = 136\nX_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, test_size=test_size, random_state=seed)\nmodel = MultinomialNB()\nmodel.fit(X_train, Y_train);"], "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "136347704_0.8524952524801488"}, "execution_count": null, "source": ["# Model Save"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "136347704_0.009277805812977213"}, "execution_count": 2, "source": ["from Notebook.DSNotebook.NotebookExecutor import NotebookExecutor\nnb = NotebookExecutor()\nsaved_model = nb.save_model(model = model, modelName = 'Model_V1', modelType = 'ml', X = None, y = None, estimator_type='')\n#X and y are training datasets to get explainer dashboard.\n#estimator_type is to specify algorithm type i.e., classification and regression.\n#Only 'ml\u2019 models with tabular data as input will support in Explainer Dashboard.\n#Choose modelType = 'ml' for machine learning models, modelType = 'cv' for computer vision models and modelType = 'dp' for data transformation pickle files. \n#Provide \u2018column_headers\u2019 as a parameter if they have to be saved in the model.\n#If using custom layer in keras, use native save functionality from keras."], "outputs": [{"name": "stdout", "text": ["WARN: Training data is not provided. Unable to generate Explainer Dashboard\n"], "output_type": "stream"}]}, {"cell_type": "markdown", "metadata": {"id": "136347704_0.5356541059407767"}, "execution_count": null, "source": ["# Model Load"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "136347704_0.3229586900807342"}, "execution_count": 3, "source": ["from Notebook.DSNotebook.NotebookExecutor import NotebookExecutor\nnb = NotebookExecutor()\nloaded_model = nb.load_saved_model('11561706704411977')"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "136347704_0.1069122258691042"}, "execution_count": 4, "source": ["X_test_copy = X_test.copy()"], "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "136347704_0.09293369866161383"}, "execution_count": 1, "source": ["# Model Predict"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "136347704_0.3851391589494544"}, "execution_count": 5, "source": ["nb.predict(model = loaded_model, dataframe = X_test_copy, modeltype='ml') \n #Choose modeltype 'ml' for machine learning models and 'cv' for computer vision model \n #ex: For machine learning model nb.predict(model = model, modeltype = 'ml', dataframe = df) \n #ex: For computer vision keras model nb.predict(model = model, modeltype = 'cv', imgs = imgs, imgsize = (28, 28), dim = 1, class_names = class_names) \n #and for pytorch model(model = model, modeltype = 'cv', imgs = imgs, class_names = class_names) \n #Note: incase any error in prediction user squeezed image data in keras"], "outputs": [{"data": {"text/plain": ["        0      1     2     3      4     5      6     7  predictions\n0     2.0  174.0  88.0  37.0  120.0  44.5  0.646  24.0          1.0\n1     2.0  155.0  52.0  27.0  540.0  38.7  0.240  25.0          1.0\n2     0.0   94.0  70.0  27.0  115.0  43.5  0.347  21.0          1.0\n3     4.0  109.0  64.0  44.0   99.0  34.8  0.905  26.0          1.0\n4     1.0   97.0  68.0  21.0    0.0  27.2  1.095  22.0          0.0\n..    ...    ...   ...   ...    ...   ...    ...   ...          ...\n249   5.0  115.0  98.0   0.0    0.0  52.9  0.209  28.0          0.0\n250  10.0  108.0  66.0   0.0    0.0  32.4  0.272  42.0          0.0\n251   2.0   92.0  52.0   0.0    0.0  30.1  0.141  22.0          0.0\n252   8.0  197.0  74.0   0.0    0.0  25.9  1.191  39.0          0.0\n253   3.0   78.0  70.0   0.0    0.0  32.5  0.270  39.0          0.0\n\n[254 rows x 9 columns]"], "text/html": ["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>predictions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2.0</td>\n      <td>174.0</td>\n      <td>88.0</td>\n      <td>37.0</td>\n      <td>120.0</td>\n      <td>44.5</td>\n      <td>0.646</td>\n      <td>24.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2.0</td>\n      <td>155.0</td>\n      <td>52.0</td>\n      <td>27.0</td>\n      <td>540.0</td>\n      <td>38.7</td>\n      <td>0.240</td>\n      <td>25.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>94.0</td>\n      <td>70.0</td>\n      <td>27.0</td>\n      <td>115.0</td>\n      <td>43.5</td>\n      <td>0.347</td>\n      <td>21.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4.0</td>\n      <td>109.0</td>\n      <td>64.0</td>\n      <td>44.0</td>\n      <td>99.0</td>\n      <td>34.8</td>\n      <td>0.905</td>\n      <td>26.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.0</td>\n      <td>97.0</td>\n      <td>68.0</td>\n      <td>21.0</td>\n      <td>0.0</td>\n      <td>27.2</td>\n      <td>1.095</td>\n      <td>22.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>249</th>\n      <td>5.0</td>\n      <td>115.0</td>\n      <td>98.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>52.9</td>\n      <td>0.209</td>\n      <td>28.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>250</th>\n      <td>10.0</td>\n      <td>108.0</td>\n      <td>66.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>32.4</td>\n      <td>0.272</td>\n      <td>42.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>251</th>\n      <td>2.0</td>\n      <td>92.0</td>\n      <td>52.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>30.1</td>\n      <td>0.141</td>\n      <td>22.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>252</th>\n      <td>8.0</td>\n      <td>197.0</td>\n      <td>74.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>25.9</td>\n      <td>1.191</td>\n      <td>39.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>253</th>\n      <td>3.0</td>\n      <td>78.0</td>\n      <td>70.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>32.5</td>\n      <td>0.270</td>\n      <td>39.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>254 rows \u00d7 9 columns</p>\n</div>"]}, "metadata": {}, "execution_count": 6, "output_type": "execute_result"}]}, {"cell_type": "code", "metadata": {"id": "136347704_0.4151349212416513"}, "execution_count": 6, "source": ["X_test_copy = X_test.copy()"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "136347704_0.5912394074353078"}, "execution_count": 7, "source": ["Y_pred = nb.predict(model = loaded_model, dataframe = X_test_copy, modeltype='ml') "], "outputs": []}, {"cell_type": "code", "metadata": {"id": "136347704_0.6989448442824169"}, "execution_count": 8, "source": ["Y_pred.head()"], "outputs": [{"data": {"text/plain": ["     0      1     2     3      4     5      6     7  predictions\n0  2.0  174.0  88.0  37.0  120.0  44.5  0.646  24.0          1.0\n1  2.0  155.0  52.0  27.0  540.0  38.7  0.240  25.0          1.0\n2  0.0   94.0  70.0  27.0  115.0  43.5  0.347  21.0          1.0\n3  4.0  109.0  64.0  44.0   99.0  34.8  0.905  26.0          1.0\n4  1.0   97.0  68.0  21.0    0.0  27.2  1.095  22.0          0.0"], "text/html": ["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>predictions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2.0</td>\n      <td>174.0</td>\n      <td>88.0</td>\n      <td>37.0</td>\n      <td>120.0</td>\n      <td>44.5</td>\n      <td>0.646</td>\n      <td>24.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2.0</td>\n      <td>155.0</td>\n      <td>52.0</td>\n      <td>27.0</td>\n      <td>540.0</td>\n      <td>38.7</td>\n      <td>0.240</td>\n      <td>25.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>94.0</td>\n      <td>70.0</td>\n      <td>27.0</td>\n      <td>115.0</td>\n      <td>43.5</td>\n      <td>0.347</td>\n      <td>21.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4.0</td>\n      <td>109.0</td>\n      <td>64.0</td>\n      <td>44.0</td>\n      <td>99.0</td>\n      <td>34.8</td>\n      <td>0.905</td>\n      <td>26.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.0</td>\n      <td>97.0</td>\n      <td>68.0</td>\n      <td>21.0</td>\n      <td>0.0</td>\n      <td>27.2</td>\n      <td>1.095</td>\n      <td>22.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}, "metadata": {}, "execution_count": 9, "output_type": "execute_result"}]}, {"cell_type": "code", "metadata": {"id": "136347704_0.8354178594465274"}, "execution_count": 9, "source": ["from sklearn.metrics import accuracy_score\naccuracy_score(Y_test, Y_pred.predictions)"], "outputs": [{"data": {"text/plain": "0.6023622047244095"}, "metadata": {}, "execution_count": 10, "output_type": "execute_result"}]}, {"cell_type": "markdown", "metadata": {"id": "136347704_0.6478625251504533"}, "execution_count": null, "source": ["# Sandbox file read"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "136347704_0.38351539593250816"}, "execution_count": 10, "source": ["from Notebook.DSNotebook.NotebookExecutor import NotebookExecutor\nnb = NotebookExecutor()\ndf_Test_Data = nb.get_data('11561706704926924', '@SYS.USERID', 'True', {}, [])\ndf_Test_Data.head()"], "outputs": [{"data": {"text/plain": ["   SNo ObservationDate Province/State  Country/Region      Last Update  Confirmed  Deaths  Recovered\n0    1      01/22/2020          Anhui  Mainland China  1/22/2020 17:00          1       0          0\n1    2      01/22/2020        Beijing  Mainland China  1/22/2020 17:00         14       0          0\n2    3      01/22/2020      Chongqing  Mainland China  1/22/2020 17:00          6       0          0\n3    4      01/22/2020         Fujian  Mainland China  1/22/2020 17:00          1       0          0\n4    5      01/22/2020          Gansu  Mainland China  1/22/2020 17:00          0       0          0"], "text/html": ["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SNo</th>\n      <th>ObservationDate</th>\n      <th>Province/State</th>\n      <th>Country/Region</th>\n      <th>Last Update</th>\n      <th>Confirmed</th>\n      <th>Deaths</th>\n      <th>Recovered</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>01/22/2020</td>\n      <td>Anhui</td>\n      <td>Mainland China</td>\n      <td>1/22/2020 17:00</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>01/22/2020</td>\n      <td>Beijing</td>\n      <td>Mainland China</td>\n      <td>1/22/2020 17:00</td>\n      <td>14</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>01/22/2020</td>\n      <td>Chongqing</td>\n      <td>Mainland China</td>\n      <td>1/22/2020 17:00</td>\n      <td>6</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>01/22/2020</td>\n      <td>Fujian</td>\n      <td>Mainland China</td>\n      <td>1/22/2020 17:00</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>01/22/2020</td>\n      <td>Gansu</td>\n      <td>Mainland China</td>\n      <td>1/22/2020 17:00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}, "metadata": {}, "execution_count": 11, "output_type": "execute_result"}]}, {"cell_type": "markdown", "metadata": {"id": "136347704_0.7809212405742656"}, "execution_count": null, "source": ["# Artifacts file save"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "136347704_0.7328623778974745"}, "execution_count": 11, "source": ["from Notebook.DSNotebook.NotebookExecutor import NotebookExecutor\nnb = NotebookExecutor()\n#File extension should be with .csv/.json/.txt\nnb.save_artifact(dataframe = df_Test_Data, name = 'df_Test_Data.txt')"], "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "136347704_0.7566945244328687"}, "execution_count": null, "source": ["# Artifacts saved file read"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "136347704_0.4936946650425271"}, "execution_count": 12, "source": ["@SYS.ARTIFACT_PATH+'df_Test_Data.txt'"], "outputs": [{"data": {"text/plain": "'@SYS.DATASANDBOX_PATH/df_Test_Data.txt'"}, "metadata": {}, "execution_count": 13, "output_type": "execute_result"}]}, {"cell_type": "code", "metadata": {"id": "136347704_0.9755846589901582"}, "execution_count": 17, "source": ["# print(open(@SYS.ARTIFACT_PATH+'df_Test_Data.txt').read())\nnum_bytes_to_read = 1000\nwith open(@SYS.ARTIFACT_PATH+'df_Test_Data.txt', 'r') as file:\n    limited_data = file.read(num_bytes_to_read)\nprint(limited_data)"], "outputs": [{"name": "stdout", "text": [",SNo,ObservationDate,Province/State,Country/Region,Last Update,Confirmed,Deaths,Recovered\n0,1,01/22/2020,Anhui,Mainland China,1/22/2020 17:00,1,0,0\n1,2,01/22/2020,Beijing,Mainland China,1/22/2020 17:00,14,0,0\n2,3,01/22/2020,Chongqing,Mainland China,1/22/2020 17:00,6,0,0\n3,4,01/22/2020,Fujian,Mainland China,1/22/2020 17:00,1,0,0\n4,5,01/22/2020,Gansu,Mainland China,1/22/2020 17:00,0,0,0\n5,6,01/22/2020,Guangdong,Mainland China,1/22/2020 17:00,26,0,0\n6,7,01/22/2020,Guangxi,Mainland China,1/22/2020 17:00,2,0,0\n7,8,01/22/2020,Guizhou,Mainland China,1/22/2020 17:00,1,0,0\n8,9,01/22/2020,Hainan,Mainland China,1/22/2020 17:00,4,0,0\n9,10,01/22/2020,Hebei,Mainland China,1/22/2020 17:00,1,0,0\n10,11,01/22/2020,Heilongjiang,Mainland China,1/22/2020 17:00,0,0,0\n11,12,01/22/2020,Henan,Mainland China,1/22/2020 17:00,5,0,0\n12,13,01/22/2020,Hong Kong,Hong Kong,1/22/2020 17:00,0,0,0\n13,14,01/22/2020,Hubei,Mainland China,1/22/2020 17:00,444,17,28\n14,15,01/22/2020,Hunan,Mainland China,1/22/2020 17:00,4,0,0\n1\n"], "output_type": "stream"}]}, {"cell_type": "markdown", "metadata": {"id": "136347704_0.048031871946919935"}, "execution_count": 1, "source": ["# Reading uploaded file in forder structure"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "136347704_0.15639625396185042"}, "execution_count": null, "source": ["@SYS.DATASANDBOX_PATH + '135823364/Data/Folder_V1/Limerick_input_V1.xlsx'"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "136347704_0.5575589737827173"}, "execution_count": 19, "source": ["pd.read_excel(@SYS.DATASANDBOX_PATH + '135823364/Data/Folder_V1/Limerick_input_V1.xlsx')"], "outputs": [{"data": {"text/plain": ["          date  Machine  Mcode  Shift DowntimeDesctiption  DD  DowntimeInHours\n0   2021-06-01   901850      1      1                Idle   2         0.850278\n1   2021-06-01   901850      1      1               Setup   3         0.000556\n2   2021-06-01   901850      1      2                Idle   2         1.929167\n3   2021-06-01   901850      1      2               Setup   3         0.034167\n4   2021-06-01   901850      1      3                Idle   2         3.436389\n..         ...      ...    ...    ...                 ...  ..              ...\n277 2021-06-28   903030      2      2               Setup   3         0.002778\n278 2021-06-29   901850      1      1                Idle   2         1.397222\n279 2021-06-29   901850      1      1               Setup   3         0.001389\n280 2021-06-29   903030      2      1                Idle   2         0.188889\n281 2021-06-29   903030      2      1               Setup   3         0.005556\n\n[282 rows x 7 columns]"], "text/html": ["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>Machine</th>\n      <th>Mcode</th>\n      <th>Shift</th>\n      <th>DowntimeDesctiption</th>\n      <th>DD</th>\n      <th>DowntimeInHours</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2021-06-01</td>\n      <td>901850</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Idle</td>\n      <td>2</td>\n      <td>0.850278</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2021-06-01</td>\n      <td>901850</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Setup</td>\n      <td>3</td>\n      <td>0.000556</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2021-06-01</td>\n      <td>901850</td>\n      <td>1</td>\n      <td>2</td>\n      <td>Idle</td>\n      <td>2</td>\n      <td>1.929167</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2021-06-01</td>\n      <td>901850</td>\n      <td>1</td>\n      <td>2</td>\n      <td>Setup</td>\n      <td>3</td>\n      <td>0.034167</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2021-06-01</td>\n      <td>901850</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Idle</td>\n      <td>2</td>\n      <td>3.436389</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>277</th>\n      <td>2021-06-28</td>\n      <td>903030</td>\n      <td>2</td>\n      <td>2</td>\n      <td>Setup</td>\n      <td>3</td>\n      <td>0.002778</td>\n    </tr>\n    <tr>\n      <th>278</th>\n      <td>2021-06-29</td>\n      <td>901850</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Idle</td>\n      <td>2</td>\n      <td>1.397222</td>\n    </tr>\n    <tr>\n      <th>279</th>\n      <td>2021-06-29</td>\n      <td>901850</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Setup</td>\n      <td>3</td>\n      <td>0.001389</td>\n    </tr>\n    <tr>\n      <th>280</th>\n      <td>2021-06-29</td>\n      <td>903030</td>\n      <td>2</td>\n      <td>1</td>\n      <td>Idle</td>\n      <td>2</td>\n      <td>0.188889</td>\n    </tr>\n    <tr>\n      <th>281</th>\n      <td>2021-06-29</td>\n      <td>903030</td>\n      <td>2</td>\n      <td>1</td>\n      <td>Setup</td>\n      <td>3</td>\n      <td>0.005556</td>\n    </tr>\n  </tbody>\n</table>\n<p>282 rows \u00d7 7 columns</p>\n</div>"]}, "metadata": {}, "execution_count": 20, "output_type": "execute_result"}]}, {"cell_type": "markdown", "metadata": {"id": "136347704_0.9621451278122577"}, "execution_count": null, "source": ["# Utility file read"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "136347704_0.5960509629912596"}, "execution_count": 0, "source": ["from Utiity_script_V33 import Person\nFuture = Person(\"Shyam\", \"29\")\nprint(Future.name)\nprint(Future.age)"], "outputs": [{"name": "stdout", "text": ["Shyam\n29\n"], "output_type": "stream"}]}, {"cell_type": "code", "metadata": {"id": "136347704_0.457772239094995"}, "execution_count": 1, "source": ["from Utiity_script_V33 import Person\nimport inspect\nsource_code = inspect.getsource(Person)\nprint(source_code)"], "outputs": [{"name": "stdout", "text": ["class Person:\n  def __init__(self, name, age):\n    self.name = name\n    self.age = age\n\n  def myfunc(self):\n    print(\"Hello my name is \" + self.name)\n\n"], "output_type": "stream"}]}, {"cell_type": "markdown", "metadata": {"id": "136347704_0.10510223556436493"}, "execution_count": null, "source": ["# Data Transformation save"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "136347704_0.659241934636869"}, "execution_count": 2, "source": ["from sklearn.datasets import make_blobs\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom pickle import dump\n# prepare dataset\nX, y = make_blobs(n_samples=100, centers=2, n_features=2, random_state=1)\n# split data into train and test sets\nX_train, _, y_train, _ = train_test_split(X, y, test_size=0.33, random_state=1)\n# define scaler\nscaler = MinMaxScaler()\n# fit scaler on the training dataset\nscaler.fit(X_train);\n# transform the training dataset\nX_train_scaled = scaler.transform(X_train)\nfrom Notebook.DSNotebook.NotebookExecutor import NotebookExecutor\nnb = NotebookExecutor()\nsaved_model = nb.save_model(model = scaler, modelName = 'ScalerTransform', modelType = 'dp', X = None, y = None, estimator_type='')\n#X and y are training datasets to get explainer dashboard.\n#estimator_type is to specify algorithm type i.e., classification and regression.\n#Only 'ml\u2019 models with tabular data as input will support in Explainer Dashboard.\n#Choose modelType = 'ml' for machine learning models, modelType = 'cv' for computer vision models and modelType = 'dp' for data transformation pickle files. \n#Provide \u2018column_headers\u2019 as a parameter if they have to be saved in the model.\n#If using custom layer in keras, use native save functionality from keras."], "outputs": [{"name": "stdout", "text": ["WARN: Training data is not provided. Unable to generate Explainer Dashboard\n"], "output_type": "stream"}]}, {"cell_type": "markdown", "metadata": {"id": "136347704_0.6705600142202406"}, "execution_count": null, "source": ["# Transformation load"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "136347704_0.4083863999144708"}, "execution_count": 3, "source": ["from Notebook.DSNotebook.NotebookExecutor import NotebookExecutor\nnb = NotebookExecutor()\nloaded_model = nb.load_model('11561706705620074')"], "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "136347704_0.5703016905372051"}, "execution_count": null, "source": ["# Transforming traing data"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "136347704_0.6427627047508815"}, "execution_count": 4, "source": ["loaded_model.transform(X_train)"], "outputs": [{"data": {"text/plain": "array([[0.23395852, 0.35842125],\n       [0.79875321, 0.90133484],\n       [0.1727263 , 0.18315143],\n       [0.73324478, 0.85530443],\n       [0.86490997, 0.81400847],\n       [0.84925052, 0.81778689],\n       [0.28151464, 0.21503406],\n       [0.83890271, 1.        ],\n       [0.11768194, 0.25272282],\n       [0.15358548, 0.17127067],\n       [0.22971925, 0.20538083],\n       [0.30388699, 0.27498359],\n       [0.17837018, 0.08705392],\n       [0.19282048, 0.19950001],\n       [0.82758701, 0.78772661],\n       [0.18570507, 0.18105428],\n       [0.21555452, 0.26981763],\n       [0.05071381, 0.23151541],\n       [0.19005398, 0.1752731 ],\n       [0.79317393, 0.78759208],\n       [0.35425701, 0.16953972],\n       [0.82689292, 0.88232276],\n       [0.81355841, 0.76455675],\n       [0.12855764, 0.19135056],\n       [0.89624055, 0.78410253],\n       [0.84206699, 0.89621938],\n       [0.9575363 , 0.89467094],\n       [0.80184776, 0.87825451],\n       [0.76255514, 0.93428527],\n       [0.1826463 , 0.23485323],\n       [0.79744376, 0.80734217],\n       [1.        , 0.72882744],\n       [0.76927084, 0.83614339],\n       [0.73459283, 0.92589868],\n       [0.83855105, 0.86892497],\n       [0.89337759, 0.65864154],\n       [0.24377251, 0.21747541],\n       [0.25293258, 0.34136975],\n       [0.17015267, 0.16581683],\n       [0.09781082, 0.25873148],\n       [0.14807041, 0.12870764],\n       [0.21408907, 0.14046659],\n       [0.15146464, 0.10180892],\n       [0.76313985, 0.96837513],\n       [0.80955751, 0.76904774],\n       [0.91505164, 0.75182912],\n       [0.32698889, 0.0417588 ],\n       [0.19210256, 0.1000778 ],\n       [0.94156966, 0.67736192],\n       [0.83332236, 0.92471684],\n       [0.79571246, 0.84050646],\n       [0.19550959, 0.20749043],\n       [0.80552738, 0.82155677],\n       [0.12501222, 0.        ],\n       [0.20498394, 0.16402074],\n       [0.2098691 , 0.11486197],\n       [0.22023356, 0.24701562],\n       [0.21839815, 0.12216597],\n       [0.16883584, 0.24175307],\n       [0.        , 0.28468564],\n       [0.78737153, 0.93208592],\n       [0.21482032, 0.19243259],\n       [0.84897559, 0.68030412],\n       [0.86293838, 0.83126495],\n       [0.19870447, 0.22141413],\n       [0.14113841, 0.14094497],\n       [0.03915974, 0.21326187]])"}, "metadata": {}, "execution_count": 5, "output_type": "execute_result"}]}], "metadata": {}, "nbformat": 4, "nbformat_minor": 2}